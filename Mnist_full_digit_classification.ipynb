{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist_full_digit_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNR7bccadny2/gc8UOCY5VS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishandahal/Fun_Projects/blob/master/Mnist_full_digit_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDpllNDaUFbV",
        "colab_type": "text"
      },
      "source": [
        "###Attempting to create a minist digit classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1duvGAmNSrXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install fastai --upgrade -q"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhYF44fCSgUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fastai\n",
        "from fastai.vision.all import *\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRqvgJ9gTAII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.MNIST)\n",
        "Path.BASE_PATH = path"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMj_U-6zUWPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16d59ab1-bc21-486c-ec7b-7aa7d4be6418"
      },
      "source": [
        "#Checking the contents of the dataset\n",
        "path.ls()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('training'),Path('testing')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni0GyJ5xcTf8",
        "colab_type": "text"
      },
      "source": [
        "###Lesson learned object needs to be modified by .ls() for it to be iterable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRx2L5mvUnvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27e80b07-8d5a-458f-df93-5e991d8486dd"
      },
      "source": [
        "#Looking at the training set only\n",
        "train_set = (path / 'training').ls().sorted()\n",
        "train_set"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('training/0'),Path('training/1'),Path('training/2'),Path('training/3'),Path('training/4'),Path('training/5'),Path('training/6'),Path('training/7'),Path('training/8'),Path('training/9')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXZjkZ8XaXn2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83ab48a8-af02-4e52-f17b-2312f254fb87"
      },
      "source": [
        "train_set[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('training/0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNapAlwQU5KR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1b1b5b9a-6ff8-45ae-904e-b162e7fe0bc7"
      },
      "source": [
        "#Let's see what the digits look like. Just the 9s.\n",
        "sample_nines = train_set[9].ls()\n",
        "sample_nines"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#5949) [Path('training/9/17107.png'),Path('training/9/41306.png'),Path('training/9/52315.png'),Path('training/9/46435.png'),Path('training/9/20333.png'),Path('training/9/31659.png'),Path('training/9/25828.png'),Path('training/9/27128.png'),Path('training/9/43324.png'),Path('training/9/3913.png')...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4lv57JfVj9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "outputId": "1b2328da-b8d4-4b97-9ff2-fbdc2da068b5"
      },
      "source": [
        "view_nine = Image.open(sample_nines[9])\n",
        "view_nine"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA00lEQVR4nGNgGLqARbPu1b9/bljl2Dr//vv79+9erHIFf/8++Pv37zsscrLnPk7M55HXe52JRfL237MMDAwMDPd0MeUC/m8zZ2BgYOBYfwbuPrjkt/+X3jX/b3Ds0fuGxdh/f9/9fXfp79+/eTARJoSk+knmC7/PbWBgOILNK4LSLCqsZ//2M2KTZGBgYEj991wEl5zyq7+luOQYKv5d4cQlp/L2XzUuObnzf9+z4JJU+/LAG5cc3/m/S3DJiR/4e04cl+TFv+ckcMkx/HuJUx/JAADZTk50MaRAowAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FC8EEB02C88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8a7iXH8hrWn",
        "colab_type": "text"
      },
      "source": [
        "###Converting images into tensors and stacking them together in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymm2bjLpi8I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zeros = train_set[0].ls().sorted()\n",
        "ones = train_set[1].ls().sorted()\n",
        "zeros = train_set"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtnU-uqUj1jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Function to create a dictionary of all the images into their respective named containers\n",
        "def dict_for_digits(path):\n",
        "    str_ = (0,1,2,3,4,5,6,7,8,9)\n",
        "    new_dict = {str_[idx]: letters.ls() for idx, letters in enumerate(path)}\n",
        "    return new_dict\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NysafyIx5yMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d0be60e-3b81-4a71-c091-845099cab252"
      },
      "source": [
        "##Going to get the test set ready while here\n",
        "test_set = path / 'testing'\n",
        "test_set = test_set.ls().sorted()\n",
        "test_set"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('testing/0'),Path('testing/1'),Path('testing/2'),Path('testing/3'),Path('testing/4'),Path('testing/5'),Path('testing/6'),Path('testing/7'),Path('testing/8'),Path('testing/9')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tigl6Td26Ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digit_dict_train = dict_for_digits(train_set)\n",
        "digit_dict_test = dict_for_digits(test_set)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFehcZDV6s7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "51f51771-7340-454e-c187-9842461cf9fd"
      },
      "source": [
        "digit_dict_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: (#5923) [Path('training/0/52804.png'),Path('training/0/27283.png'),Path('training/0/9966.png'),Path('training/0/33214.png'),Path('training/0/19303.png'),Path('training/0/4488.png'),Path('training/0/43613.png'),Path('training/0/4926.png'),Path('training/0/5844.png'),Path('training/0/41358.png')...],\n",
              " 1: (#6742) [Path('training/1/49392.png'),Path('training/1/26745.png'),Path('training/1/8648.png'),Path('training/1/53206.png'),Path('training/1/27789.png'),Path('training/1/49308.png'),Path('training/1/18852.png'),Path('training/1/5966.png'),Path('training/1/27657.png'),Path('training/1/8625.png')...],\n",
              " 2: (#5958) [Path('training/2/1662.png'),Path('training/2/21623.png'),Path('training/2/472.png'),Path('training/2/55508.png'),Path('training/2/47369.png'),Path('training/2/5318.png'),Path('training/2/54052.png'),Path('training/2/44934.png'),Path('training/2/5129.png'),Path('training/2/48986.png')...],\n",
              " 3: (#6131) [Path('training/3/40940.png'),Path('training/3/55876.png'),Path('training/3/27726.png'),Path('training/3/20675.png'),Path('training/3/17967.png'),Path('training/3/22619.png'),Path('training/3/24867.png'),Path('training/3/23747.png'),Path('training/3/58881.png'),Path('training/3/17403.png')...],\n",
              " 4: (#5842) [Path('training/4/15942.png'),Path('training/4/23596.png'),Path('training/4/11255.png'),Path('training/4/11460.png'),Path('training/4/45184.png'),Path('training/4/12285.png'),Path('training/4/40334.png'),Path('training/4/36909.png'),Path('training/4/9496.png'),Path('training/4/41528.png')...],\n",
              " 5: (#5421) [Path('training/5/23200.png'),Path('training/5/12829.png'),Path('training/5/11359.png'),Path('training/5/51298.png'),Path('training/5/54189.png'),Path('training/5/24077.png'),Path('training/5/49928.png'),Path('training/5/31772.png'),Path('training/5/43882.png'),Path('training/5/26404.png')...],\n",
              " 6: (#5918) [Path('training/6/11832.png'),Path('training/6/16425.png'),Path('training/6/15708.png'),Path('training/6/26114.png'),Path('training/6/35213.png'),Path('training/6/23569.png'),Path('training/6/1020.png'),Path('training/6/57891.png'),Path('training/6/45080.png'),Path('training/6/57881.png')...],\n",
              " 7: (#6265) [Path('training/7/27392.png'),Path('training/7/26255.png'),Path('training/7/42265.png'),Path('training/7/46053.png'),Path('training/7/54638.png'),Path('training/7/22754.png'),Path('training/7/36611.png'),Path('training/7/8805.png'),Path('training/7/4832.png'),Path('training/7/10002.png')...],\n",
              " 8: (#5851) [Path('training/8/7872.png'),Path('training/8/16467.png'),Path('training/8/6792.png'),Path('training/8/40945.png'),Path('training/8/37715.png'),Path('training/8/40453.png'),Path('training/8/4021.png'),Path('training/8/20315.png'),Path('training/8/4139.png'),Path('training/8/13436.png')...],\n",
              " 9: (#5949) [Path('training/9/17107.png'),Path('training/9/41306.png'),Path('training/9/52315.png'),Path('training/9/46435.png'),Path('training/9/20333.png'),Path('training/9/31659.png'),Path('training/9/25828.png'),Path('training/9/27128.png'),Path('training/9/43324.png'),Path('training/9/3913.png')...]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf9E1MWI7lxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing tensor conversion before creating a function\n",
        "tensor(Image.open(digit_dict_train[0][0]))\n",
        "tnsr_0 = torch.stack([tensor(Image.open(o)) for o in digit_dict_train[0]])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH9oeqyhBWm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e007d63-1882-4044-c4ed-f0df953acd2b"
      },
      "source": [
        "tnsr_0.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5923, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJrP31pP31X4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Converting images into tensors and stacking\n",
        "## Function that converts one folder of images to tensors\n",
        "\n",
        "def img_to_tnsr(folder):\n",
        "    \"\"\"Converts iterable images into tensors and stacks them\"\"\"\n",
        "    return torch.stack([tensor(Image.open(i)) for i in folder]).float() / 255.0\n",
        "\n",
        "def agg_tnsr_imgs(dicts):\n",
        "    \"\"\"Takes in dictionary of images and converts to stacked tensors\"\"\"\n",
        "    tnsr_folder = [img_to_tnsr(dicts[key]) for key, value in dicts.items()]\n",
        "    agged_tnsrs = torch.cat(tnsr_folder[:])\n",
        "    return agged_tnsrs\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNcHYSZxd8UQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Creating one hot encoded vectors (labels) for the dataset\n",
        "## Using the dictionary as a guide\n",
        "def one_hot_label(rows, cols, index):\n",
        "\n",
        "    shape_of_vector = torch.zeros([rows,cols])\n",
        "    shape_of_vector[:, index] = 1\n",
        "    return shape_of_vector\n",
        "\n",
        "def label_all(dicts):\n",
        "    labels = [one_hot_label(len(values), len(dicts.keys()), keys) for keys,values in dicts.items()]\n",
        "    labels = torch.cat(labels[:])\n",
        "    return labels\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOhaolLgieaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training and test set with all the images converted to tensor, stacked and concatenated\n",
        "train_x = agg_tnsr_imgs(digit_dict_train)\n",
        "test_x = agg_tnsr_imgs(digit_dict_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfxV4PFFieOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "62aa8c09-cc97-445d-a455-540cea6a5254"
      },
      "source": [
        "show_image(test_x[1500]);"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADJklEQVR4nO2bQU/qWhRGVws9TVvARig6UGOciDEx0Z/ryB/h/yCONAwYkDDAmBSBVktpe0fcxz3xxTe57OZ5VtIBMOiXlXO6d3eLVVUVhn+wpQPUDSNEwwjRMEI0jBCN5je//59LkPXVl2aFaBghGkaIhhGiYYRoGCEa35XdvZGmKYvFAs/zcBzn97FvaiNkOBzy8PDA3d0dNzc3XF5e0uv19p6jVlvGtm0cx8F1XWxbJlothFRVRRiGDAYDrq+vOT09xfM8kSziQvI8J01TZrMZ4/GYxWKBbdtY1ped9V9HXEiSJIzHYx4fH7m/v+fp6YmqqpCa5IkLqaqKsizZbDbkeU4cx8RxTJ7nInnEhViW9ccWmU6nDIdD3t/fRfKIC9GxbZtms/mzq8wuSina7TaNRkPk/OJCPj8/ieOYJEkA2Gw2fHx8UJalSB5xIUmS8PLyQhzHAGRZxnw+/7kX1W2V+bfP+0ZcSN2onZAwDLm4uPi5rbtOFEWcn5/j+77I+WsnxHEclFKmD9milDK3/3XCCNEwQjSMEA1xIUVRkKYpSimOj4/p9/t4nkezKTP/Fp+6l2VJlmUopTg6OqLb7YpWGXEh8/mc5+dnkiSh1+vh+76YDKjBllksFoxGI5bLJQcHByilsCzr5w2ZN5sNaZoynU6ZTCYEQcBgMCAMQ6lIgLCQLMuI45i3tzdc1+Xs7IwgCKQiAcJbpqoqiqKgKArRGcgu4kJ2jzogJqTRaOB5Ht1ulyiKxOYfOmJCbNum0Wjg+z5BEOA4jlhl2UWsD9kOkyeTCbPZjLIsOTw8FHknZBfRKrNcLpnP56RpimVZtFotsecxW8RWyGq1YjQasVqt6Pf7XF1dcXt7S7vdlooECArJ85zX11fW6zWe5xFFEZ1OR+ymbov4vYxSik6nQ7vd/t22SyIuxLZtXNcVHSz/kUc6gO/7nJyciLfsW0T7kCAICMOQfr8v9hxGx/qmZf5r/fR6vSbLMoqiYL1e02q19i3ly4uVmJAaYP4v818wQjSMEA0jRMMI0TBCNL5r3eUnNnvGrBANI0TDCNEwQjSMEA0jROMXgb8UIsHCXoIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc6zV3esieDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1ceffc8-fa04-4099-d010-83fa45610a6c"
      },
      "source": [
        "##Checking the data type \n",
        "train_x.dtype, test_x.dtype"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En1GGXFl5aro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ae74e24-8507-4334-9a94-4323357bb149"
      },
      "source": [
        "train_x.shape, test_x.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSs8k5Wk_Gug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Creating training and testing labels\n",
        "train_y = label_all(digit_dict_train)\n",
        "test_y = label_all(digit_dict_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB31JuHTfr21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8ff408a-64b2-444d-9146-027358e77fba"
      },
      "source": [
        "train_y.shape, test_y.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 10]), torch.Size([10000, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xxXw0eHcSzX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e074308d-1d45-45ca-b2b2-d65f776dc12b"
      },
      "source": [
        "train_x.shape, test_x.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ilfk212ciuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Flattening the inputs for test and training set\n",
        "## Adding an extra rank for the linear model computation\n",
        "train_x = train_x.view(-1, 28*28)\n",
        "test_x = test_x.view(-1, 28*28)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAj0QSQVdBmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8197ec24-6575-4464-82bc-917681eb88cb"
      },
      "source": [
        "# train_x[0].shape, test_x[0].shape\n",
        "train_x.shape, test_x.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 784]), torch.Size([10000, 784]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8stzPgY9dXyG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "489356d2-8553-4f2f-f6d0-555fb59b77c6"
      },
      "source": [
        "## Collating training inputs and labels\n",
        "dset = list(zip(train_x, train_y))\n",
        "x, y = dset[0]\n",
        "x.shape, y.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), torch.Size([10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv6hAu15fCY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48513413-60a8-46d1-f1ee-4685ff377efd"
      },
      "source": [
        "#Preparing the Test set\n",
        "dset_test = list(zip(test_x, test_y))\n",
        "x, y = dset_test[0]\n",
        "x.shape, y.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), torch.Size([10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qo2MBKzjnCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Creating dataloader with the training set and test set\n",
        "dls = DataLoader(dset, bs=64, shuffle=True)\n",
        "dls_test = DataLoader(dset_test, bs=64)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWhHyzelgWPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52c12acd-df38-4570-d701-ed05eb1bced7"
      },
      "source": [
        "x, y = dls.one_batch()\n",
        "x.shape, y.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 784]), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOZYWliYnDwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Initializing parameters(weights and biases)\n",
        "def init_params():\n",
        "    return torch.rand(28*28, 10).requires_grad_() , torch.rand(10).requires_grad_()\n",
        "\n",
        "#Simple one layer Linear Model \n",
        "def linear1(input):\n",
        "    #input dimension n,28*28\n",
        "    #weight dimension 28*28, 10\n",
        "    #bias dimension 10, 1\n",
        "    #output dimension n,10\n",
        "    return input @ weights + bias"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtESf5HEgFoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Loss function \n",
        "## Going to need cross entropy loss function\n",
        "## Had a tough time implementing softmax on torch. Kept running into numerical\n",
        "## Solution is to remove subtract max from numerator\n",
        "# instability on the first row which threw made loss function nan. \n",
        "def soft_max(preds):\n",
        "    \"Takes predictions from the final layer and return probabilities\"\n",
        "    # return torch.exp(preds) / torch.sum(torch.exp(preds), dim=1).view(-1,1)\n",
        "    return preds.softmax(dim=1)\n",
        "    # return exp(preds) / exp(preds).sum(dim=0, keepdim=True) #Applying softmax to get probabilities\n",
        "\n",
        "\n",
        "def neg_log_like(preds, targs):\n",
        "    \"Takes the probabilities from softmax and returns average loss\"\n",
        "    return -(preds.log() * targs).sum() / len(preds)\n",
        "\n",
        "\n",
        "def cross_entropy(preds, targs):\n",
        "    \"Putting softmax and neg-log together\"\n",
        "    soft = soft_max(preds)\n",
        "    return neg_log_like(soft, targs)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU9-TBbrh4zx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01c254a1-342c-42e3-b41a-5bd26fe7e22f"
      },
      "source": [
        "## Performing a simple forward pass.\n",
        "images, label = dls.one_batch()\n",
        "weights, bias = init_params()\n",
        "preds = linear1(images)\n",
        "loss = cross_entropy(preds, label)\n",
        "loss"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.2534, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF8WiiOhix40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrlCMoIWi8Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-3\n",
        "weights.data -= lr * weights.grad\n",
        "bias.data -= lr * bias.grad"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkIFvI4AjWL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights.grad = None\n",
        "bias.grad = None"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zJc6EmCjY15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be99352d-beca-4962-95ed-a55fc6f6d5bb"
      },
      "source": [
        "## Checking to see if the loss decreased.\n",
        "preds = linear1(images)\n",
        "loss = cross_entropy(preds, label)\n",
        "loss"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.2469, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RztKZ4Tr_KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Calculating the gradient, taking the step and zeroizing the gradient\n",
        "\n",
        "def calc_grad_n_step(loss_, lr):\n",
        "    loss_.backward()\n",
        "    weights.data -= lr * weights.grad\n",
        "    bias.data -= lr * bias.grad\n",
        "    weights.grad, bias.grad = None, None\n",
        "\n",
        "def train_batch(lr):\n",
        "    for x,y in dls:\n",
        "        preds = linear1(x)\n",
        "        loss = cross_entropy(preds, y)\n",
        "        calc_grad_n_step(loss, lr)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huviVoj1mBzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Calculating accuracy\n",
        "def acc_of_data(dls, model):\n",
        "    x, y = dls \n",
        "    preds = model(x)\n",
        "    probs = soft_max(preds)\n",
        "    return (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).float().mean()\n",
        "\n",
        "\n",
        "def val_epoch(dls):\n",
        "    stacked_acc = [acc_of_data(batch, linear1) for batch in dls]\n",
        "    return torch.stack(stacked_acc).mean()\n",
        "\n",
        "## generic accuracy calculator from predictions and targets\n",
        "def cal_accuracy(preds, y):\n",
        "    probs = soft_max(preds)\n",
        "    return (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).float().mean()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXDe8fxC7IaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Alternate accuracy metric\n",
        "def acc_of_data_(preds, targs):\n",
        "    probs = soft_max(preds)\n",
        "    return (torch.argmax(probs, dim=1) == torch.argmax(targs, dim=1)).float().mean()\n",
        "\n",
        "\n",
        "def val_epoch_(dls):\n",
        "    stacked_acc = [acc_of_data(linear1(x), y) for x,y in dls]\n",
        "    return torch.stack(stacked_acc).mean()\n",
        "\n",
        "def predict_(x,y):\n",
        "    preds = linear1(x)\n",
        "    prob = preds.softmax(dim=0)\n",
        "    prediction = torch.argmax(prob)\n",
        "    true_label = torch.argmax(y)\n",
        "    print(f\"Prediction: {prediction} : Correct label {true_label}\") \n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U_JtivdmOMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61e2dc97-6582-481c-9749-890c36e9b491"
      },
      "source": [
        "val_epoch(dls_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1305)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfp7eu5Gnkro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5716a229-8b7f-4aeb-9e18-43468fe37da9"
      },
      "source": [
        "for _ in range(40):\n",
        "    train_batch(lr=lr)\n",
        "    print(f'{val_epoch(dls_test):.4f}', end=' ')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2050 0.3364 0.4522 0.5320 0.5889 0.6273 0.6574 0.6806 0.7024 0.7193 0.7349 0.7457 0.7561 0.7654 0.7724 0.7810 0.7881 0.7946 0.8007 0.8054 0.8102 0.8144 0.8183 0.8216 0.8247 0.8268 0.8296 0.8325 0.8354 0.8374 0.8416 0.8430 0.8446 0.8458 0.8474 0.8487 0.8493 0.8508 0.8530 0.8548 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-2NU7vim7fy",
        "colab_type": "text"
      },
      "source": [
        "###Let's visualize what the weights look like after training.\n",
        "Looking at 3 out of the 10 units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDgnIZ0qkDCZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "7b86ba64-cf64-4c33-8339-416eea2b9f70"
      },
      "source": [
        "img_weight0 = weights[:,0].view(28,-1)\n",
        "img_weight1 = weights[:,1].view(28,-1)\n",
        "img_weight2 = weights[:,2].view(28,-1)\n",
        "\n",
        "show_image(img_weight1, figsize=(3,3), title='Vizualizing one of the units in the network');\n",
        "show_image(img_weight0, figsize=(3,3), title='Vizualizing one of the units in the network');\n",
        "show_image(img_weight0, figsize=(3,3), title='Vizualizing one of the units in the network');"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_dNaD0To6EE",
        "colab_type": "text"
      },
      "source": [
        "###**Let's see if we can try and predict some samples.** \n",
        "We can see from the data below that the classifier does a pretty good job! \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXp6Pf0Fl_Zo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8307f385-08fc-4c51-da86-98305b3e1fcc"
      },
      "source": [
        "### \n",
        "image, label = dset_test[0]\n",
        "prediction = predict_(image, label)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: 0 : Correct label 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcDzxoDvrWZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "8fa96420-28e1-4c31-9a29-17ef7a3b1d95"
      },
      "source": [
        "###Now let's randomly grab a number and use that as in index to grab digit.\n",
        "idx = torch.randint(0,10000, (5,1)) ## We have 10000 images in the test set.\n",
        "for idx in idx:\n",
        "    image, label = dset_test[idx]\n",
        "    prediction = predict_(image, label)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: 4 : Correct label 4\n",
            "Prediction: 7 : Correct label 7\n",
            "Prediction: 1 : Correct label 1\n",
            "Prediction: 4 : Correct label 4\n",
            "Prediction: 2 : Correct label 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0gdhNB-tYJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_grad(x, y, model):\n",
        "        preds = model(x)\n",
        "        loss = cross_entropy(preds, y)\n",
        "        print(loss)\n",
        "        loss.backward()"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHspK2hXt4xC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63a84eb2-8f16-4698-c46f-a5d94b380539"
      },
      "source": [
        "batch = train_x[:10]\n",
        "calc_grad(batch, train_y[:10], linear1)\n",
        "weights.grad.mean(), bias.grad.mean()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-1.2164e-10), tensor(-1.9791e-10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GMbMVhLo-HO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Creating an optimizer\n",
        "class Optim():\n",
        "    def __init__(self, params, lr):\n",
        "        self.params = list(params)\n",
        "        self.lr = lr\n",
        "    \n",
        "    def step(self):\n",
        "        for p in self.params:\n",
        "            p.data -= p.grad.data * self.lr\n",
        "    \n",
        "    def zero_grad(self):\n",
        "        for p in self.params:\n",
        "            p.grad = None"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_dIDItLtA3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights, bias = init_params()\n",
        "optim = Optim((weights, bias), lr)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jofx773DwDM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "aa4b4d85-3bf5-4d1f-f1f8-a5a61022f555"
      },
      "source": [
        "optim.params"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
              "         [nan, nan, nan,  ..., nan, nan, nan],\n",
              "         [nan, nan, nan,  ..., nan, nan, nan],\n",
              "         ...,\n",
              "         [nan, nan, nan,  ..., nan, nan, nan],\n",
              "         [nan, nan, nan,  ..., nan, nan, nan],\n",
              "         [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True),\n",
              " tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu1Ru5tGtfXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### New modified training epoch func\n",
        "def train_epoch(model, optim):\n",
        "    for images, labels in dls:\n",
        "        calc_grad(images, labels, linear1)\n",
        "        optim.step()\n",
        "        optim.zero_grad"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQo38N-dus7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ef1b6c4-e386-466b-c985-1f84f210d2e8"
      },
      "source": [
        "## Not sure what the issue is here. \n",
        "## The the weights end up becoming nan while taking the gradient steps.\n",
        "## This throws off the calculations.\n",
        "## Below is the print of the losses.  \n",
        "for _ in range(1):\n",
        "        train_epoch(linear1, optim)\n",
        "        print(f'{val_epoch(dls_test):.4f}', end=' ')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4.2447, grad_fn=<DivBackward0>)\n",
            "tensor(5.2476, grad_fn=<DivBackward0>)\n",
            "tensor(4.5070, grad_fn=<DivBackward0>)\n",
            "tensor(4.5015, grad_fn=<DivBackward0>)\n",
            "tensor(4.1273, grad_fn=<DivBackward0>)\n",
            "tensor(4.5188, grad_fn=<DivBackward0>)\n",
            "tensor(4.7437, grad_fn=<DivBackward0>)\n",
            "tensor(4.9857, grad_fn=<DivBackward0>)\n",
            "tensor(4.1537, grad_fn=<DivBackward0>)\n",
            "tensor(4.6909, grad_fn=<DivBackward0>)\n",
            "tensor(4.2757, grad_fn=<DivBackward0>)\n",
            "tensor(4.3858, grad_fn=<DivBackward0>)\n",
            "tensor(4.0716, grad_fn=<DivBackward0>)\n",
            "tensor(3.9780, grad_fn=<DivBackward0>)\n",
            "tensor(4.0508, grad_fn=<DivBackward0>)\n",
            "tensor(4.1054, grad_fn=<DivBackward0>)\n",
            "tensor(3.8127, grad_fn=<DivBackward0>)\n",
            "tensor(4.2211, grad_fn=<DivBackward0>)\n",
            "tensor(4.2551, grad_fn=<DivBackward0>)\n",
            "tensor(4.0767, grad_fn=<DivBackward0>)\n",
            "tensor(4.1886, grad_fn=<DivBackward0>)\n",
            "tensor(3.9754, grad_fn=<DivBackward0>)\n",
            "tensor(3.7724, grad_fn=<DivBackward0>)\n",
            "tensor(3.6204, grad_fn=<DivBackward0>)\n",
            "tensor(3.8509, grad_fn=<DivBackward0>)\n",
            "tensor(4.0521, grad_fn=<DivBackward0>)\n",
            "tensor(3.7762, grad_fn=<DivBackward0>)\n",
            "tensor(3.3218, grad_fn=<DivBackward0>)\n",
            "tensor(3.4880, grad_fn=<DivBackward0>)\n",
            "tensor(3.6137, grad_fn=<DivBackward0>)\n",
            "tensor(2.9174, grad_fn=<DivBackward0>)\n",
            "tensor(3.1823, grad_fn=<DivBackward0>)\n",
            "tensor(3.1339, grad_fn=<DivBackward0>)\n",
            "tensor(3.2466, grad_fn=<DivBackward0>)\n",
            "tensor(2.9193, grad_fn=<DivBackward0>)\n",
            "tensor(3.5124, grad_fn=<DivBackward0>)\n",
            "tensor(2.6935, grad_fn=<DivBackward0>)\n",
            "tensor(3.3951, grad_fn=<DivBackward0>)\n",
            "tensor(2.9822, grad_fn=<DivBackward0>)\n",
            "tensor(3.6248, grad_fn=<DivBackward0>)\n",
            "tensor(3.3600, grad_fn=<DivBackward0>)\n",
            "tensor(2.8857, grad_fn=<DivBackward0>)\n",
            "tensor(2.7446, grad_fn=<DivBackward0>)\n",
            "tensor(2.8518, grad_fn=<DivBackward0>)\n",
            "tensor(2.3777, grad_fn=<DivBackward0>)\n",
            "tensor(3.0573, grad_fn=<DivBackward0>)\n",
            "tensor(2.7877, grad_fn=<DivBackward0>)\n",
            "tensor(2.4503, grad_fn=<DivBackward0>)\n",
            "tensor(3.0769, grad_fn=<DivBackward0>)\n",
            "tensor(2.7012, grad_fn=<DivBackward0>)\n",
            "tensor(2.5646, grad_fn=<DivBackward0>)\n",
            "tensor(3.1835, grad_fn=<DivBackward0>)\n",
            "tensor(3.0121, grad_fn=<DivBackward0>)\n",
            "tensor(3.0528, grad_fn=<DivBackward0>)\n",
            "tensor(2.3144, grad_fn=<DivBackward0>)\n",
            "tensor(2.9846, grad_fn=<DivBackward0>)\n",
            "tensor(2.6555, grad_fn=<DivBackward0>)\n",
            "tensor(3.2311, grad_fn=<DivBackward0>)\n",
            "tensor(3.0321, grad_fn=<DivBackward0>)\n",
            "tensor(3.2282, grad_fn=<DivBackward0>)\n",
            "tensor(2.3943, grad_fn=<DivBackward0>)\n",
            "tensor(2.4446, grad_fn=<DivBackward0>)\n",
            "tensor(2.5084, grad_fn=<DivBackward0>)\n",
            "tensor(2.5240, grad_fn=<DivBackward0>)\n",
            "tensor(2.3717, grad_fn=<DivBackward0>)\n",
            "tensor(2.1952, grad_fn=<DivBackward0>)\n",
            "tensor(2.2459, grad_fn=<DivBackward0>)\n",
            "tensor(2.5976, grad_fn=<DivBackward0>)\n",
            "tensor(2.6745, grad_fn=<DivBackward0>)\n",
            "tensor(2.5208, grad_fn=<DivBackward0>)\n",
            "tensor(2.0191, grad_fn=<DivBackward0>)\n",
            "tensor(2.2395, grad_fn=<DivBackward0>)\n",
            "tensor(2.6916, grad_fn=<DivBackward0>)\n",
            "tensor(2.2649, grad_fn=<DivBackward0>)\n",
            "tensor(2.4669, grad_fn=<DivBackward0>)\n",
            "tensor(2.5729, grad_fn=<DivBackward0>)\n",
            "tensor(1.6989, grad_fn=<DivBackward0>)\n",
            "tensor(2.3035, grad_fn=<DivBackward0>)\n",
            "tensor(1.7768, grad_fn=<DivBackward0>)\n",
            "tensor(2.3441, grad_fn=<DivBackward0>)\n",
            "tensor(2.2286, grad_fn=<DivBackward0>)\n",
            "tensor(1.9912, grad_fn=<DivBackward0>)\n",
            "tensor(1.6564, grad_fn=<DivBackward0>)\n",
            "tensor(1.2962, grad_fn=<DivBackward0>)\n",
            "tensor(2.0694, grad_fn=<DivBackward0>)\n",
            "tensor(1.4115, grad_fn=<DivBackward0>)\n",
            "tensor(1.5223, grad_fn=<DivBackward0>)\n",
            "tensor(1.5369, grad_fn=<DivBackward0>)\n",
            "tensor(1.4297, grad_fn=<DivBackward0>)\n",
            "tensor(1.6470, grad_fn=<DivBackward0>)\n",
            "tensor(1.3721, grad_fn=<DivBackward0>)\n",
            "tensor(1.5269, grad_fn=<DivBackward0>)\n",
            "tensor(1.3433, grad_fn=<DivBackward0>)\n",
            "tensor(1.4479, grad_fn=<DivBackward0>)\n",
            "tensor(1.3833, grad_fn=<DivBackward0>)\n",
            "tensor(1.1890, grad_fn=<DivBackward0>)\n",
            "tensor(1.0642, grad_fn=<DivBackward0>)\n",
            "tensor(1.1766, grad_fn=<DivBackward0>)\n",
            "tensor(0.8848, grad_fn=<DivBackward0>)\n",
            "tensor(0.7564, grad_fn=<DivBackward0>)\n",
            "tensor(1.2444, grad_fn=<DivBackward0>)\n",
            "tensor(1.2939, grad_fn=<DivBackward0>)\n",
            "tensor(1.1437, grad_fn=<DivBackward0>)\n",
            "tensor(1.0455, grad_fn=<DivBackward0>)\n",
            "tensor(1.0191, grad_fn=<DivBackward0>)\n",
            "tensor(1.0658, grad_fn=<DivBackward0>)\n",
            "tensor(1.1972, grad_fn=<DivBackward0>)\n",
            "tensor(0.9727, grad_fn=<DivBackward0>)\n",
            "tensor(0.9657, grad_fn=<DivBackward0>)\n",
            "tensor(1.1049, grad_fn=<DivBackward0>)\n",
            "tensor(0.7615, grad_fn=<DivBackward0>)\n",
            "tensor(0.7010, grad_fn=<DivBackward0>)\n",
            "tensor(1.1616, grad_fn=<DivBackward0>)\n",
            "tensor(0.7665, grad_fn=<DivBackward0>)\n",
            "tensor(0.9889, grad_fn=<DivBackward0>)\n",
            "tensor(0.7671, grad_fn=<DivBackward0>)\n",
            "tensor(1.0067, grad_fn=<DivBackward0>)\n",
            "tensor(0.9312, grad_fn=<DivBackward0>)\n",
            "tensor(0.8941, grad_fn=<DivBackward0>)\n",
            "tensor(0.9300, grad_fn=<DivBackward0>)\n",
            "tensor(0.9256, grad_fn=<DivBackward0>)\n",
            "tensor(0.8192, grad_fn=<DivBackward0>)\n",
            "tensor(0.8211, grad_fn=<DivBackward0>)\n",
            "tensor(0.9932, grad_fn=<DivBackward0>)\n",
            "tensor(1.1075, grad_fn=<DivBackward0>)\n",
            "tensor(1.5199, grad_fn=<DivBackward0>)\n",
            "tensor(1.1164, grad_fn=<DivBackward0>)\n",
            "tensor(1.2780, grad_fn=<DivBackward0>)\n",
            "tensor(1.1717, grad_fn=<DivBackward0>)\n",
            "tensor(1.1757, grad_fn=<DivBackward0>)\n",
            "tensor(0.8289, grad_fn=<DivBackward0>)\n",
            "tensor(0.9623, grad_fn=<DivBackward0>)\n",
            "tensor(1.1131, grad_fn=<DivBackward0>)\n",
            "tensor(1.2601, grad_fn=<DivBackward0>)\n",
            "tensor(0.9242, grad_fn=<DivBackward0>)\n",
            "tensor(1.0287, grad_fn=<DivBackward0>)\n",
            "tensor(1.1912, grad_fn=<DivBackward0>)\n",
            "tensor(1.2174, grad_fn=<DivBackward0>)\n",
            "tensor(1.0264, grad_fn=<DivBackward0>)\n",
            "tensor(1.1165, grad_fn=<DivBackward0>)\n",
            "tensor(1.2128, grad_fn=<DivBackward0>)\n",
            "tensor(1.1486, grad_fn=<DivBackward0>)\n",
            "tensor(0.7955, grad_fn=<DivBackward0>)\n",
            "tensor(0.9936, grad_fn=<DivBackward0>)\n",
            "tensor(1.0972, grad_fn=<DivBackward0>)\n",
            "tensor(0.8684, grad_fn=<DivBackward0>)\n",
            "tensor(0.9011, grad_fn=<DivBackward0>)\n",
            "tensor(1.1507, grad_fn=<DivBackward0>)\n",
            "tensor(0.9338, grad_fn=<DivBackward0>)\n",
            "tensor(1.4374, grad_fn=<DivBackward0>)\n",
            "tensor(0.8474, grad_fn=<DivBackward0>)\n",
            "tensor(1.0508, grad_fn=<DivBackward0>)\n",
            "tensor(1.5371, grad_fn=<DivBackward0>)\n",
            "tensor(0.9998, grad_fn=<DivBackward0>)\n",
            "tensor(0.7946, grad_fn=<DivBackward0>)\n",
            "tensor(1.1244, grad_fn=<DivBackward0>)\n",
            "tensor(1.1792, grad_fn=<DivBackward0>)\n",
            "tensor(1.5868, grad_fn=<DivBackward0>)\n",
            "tensor(0.7938, grad_fn=<DivBackward0>)\n",
            "tensor(1.4122, grad_fn=<DivBackward0>)\n",
            "tensor(0.9383, grad_fn=<DivBackward0>)\n",
            "tensor(0.8169, grad_fn=<DivBackward0>)\n",
            "tensor(0.5741, grad_fn=<DivBackward0>)\n",
            "tensor(0.8859, grad_fn=<DivBackward0>)\n",
            "tensor(1.0922, grad_fn=<DivBackward0>)\n",
            "tensor(0.9859, grad_fn=<DivBackward0>)\n",
            "tensor(0.7799, grad_fn=<DivBackward0>)\n",
            "tensor(1.2778, grad_fn=<DivBackward0>)\n",
            "tensor(1.1604, grad_fn=<DivBackward0>)\n",
            "tensor(0.8309, grad_fn=<DivBackward0>)\n",
            "tensor(1.1251, grad_fn=<DivBackward0>)\n",
            "tensor(0.8068, grad_fn=<DivBackward0>)\n",
            "tensor(0.6039, grad_fn=<DivBackward0>)\n",
            "tensor(0.7031, grad_fn=<DivBackward0>)\n",
            "tensor(1.1517, grad_fn=<DivBackward0>)\n",
            "tensor(0.9671, grad_fn=<DivBackward0>)\n",
            "tensor(0.9251, grad_fn=<DivBackward0>)\n",
            "tensor(0.8806, grad_fn=<DivBackward0>)\n",
            "tensor(0.6880, grad_fn=<DivBackward0>)\n",
            "tensor(0.9590, grad_fn=<DivBackward0>)\n",
            "tensor(1.6029, grad_fn=<DivBackward0>)\n",
            "tensor(0.7768, grad_fn=<DivBackward0>)\n",
            "tensor(0.8131, grad_fn=<DivBackward0>)\n",
            "tensor(1.0415, grad_fn=<DivBackward0>)\n",
            "tensor(1.2903, grad_fn=<DivBackward0>)\n",
            "tensor(0.9883, grad_fn=<DivBackward0>)\n",
            "tensor(1.2936, grad_fn=<DivBackward0>)\n",
            "tensor(0.4145, grad_fn=<DivBackward0>)\n",
            "tensor(0.8028, grad_fn=<DivBackward0>)\n",
            "tensor(0.6898, grad_fn=<DivBackward0>)\n",
            "tensor(1.2768, grad_fn=<DivBackward0>)\n",
            "tensor(0.4649, grad_fn=<DivBackward0>)\n",
            "tensor(1.0465, grad_fn=<DivBackward0>)\n",
            "tensor(1.0472, grad_fn=<DivBackward0>)\n",
            "tensor(1.1488, grad_fn=<DivBackward0>)\n",
            "tensor(0.7558, grad_fn=<DivBackward0>)\n",
            "tensor(0.8117, grad_fn=<DivBackward0>)\n",
            "tensor(0.8534, grad_fn=<DivBackward0>)\n",
            "tensor(1.1746, grad_fn=<DivBackward0>)\n",
            "tensor(0.3847, grad_fn=<DivBackward0>)\n",
            "tensor(1.3384, grad_fn=<DivBackward0>)\n",
            "tensor(0.2557, grad_fn=<DivBackward0>)\n",
            "tensor(0.8319, grad_fn=<DivBackward0>)\n",
            "tensor(0.5187, grad_fn=<DivBackward0>)\n",
            "tensor(1.0154, grad_fn=<DivBackward0>)\n",
            "tensor(1.0748, grad_fn=<DivBackward0>)\n",
            "tensor(0.8226, grad_fn=<DivBackward0>)\n",
            "tensor(0.5961, grad_fn=<DivBackward0>)\n",
            "tensor(0.4071, grad_fn=<DivBackward0>)\n",
            "tensor(1.0689, grad_fn=<DivBackward0>)\n",
            "tensor(0.4908, grad_fn=<DivBackward0>)\n",
            "tensor(0.7302, grad_fn=<DivBackward0>)\n",
            "tensor(1.0109, grad_fn=<DivBackward0>)\n",
            "tensor(1.0557, grad_fn=<DivBackward0>)\n",
            "tensor(1.1288, grad_fn=<DivBackward0>)\n",
            "tensor(0.6982, grad_fn=<DivBackward0>)\n",
            "tensor(0.6039, grad_fn=<DivBackward0>)\n",
            "tensor(0.8663, grad_fn=<DivBackward0>)\n",
            "tensor(1.5301, grad_fn=<DivBackward0>)\n",
            "tensor(1.0775, grad_fn=<DivBackward0>)\n",
            "tensor(0.5694, grad_fn=<DivBackward0>)\n",
            "tensor(0.5908, grad_fn=<DivBackward0>)\n",
            "tensor(0.8201, grad_fn=<DivBackward0>)\n",
            "tensor(0.9939, grad_fn=<DivBackward0>)\n",
            "tensor(1.0625, grad_fn=<DivBackward0>)\n",
            "tensor(0.4775, grad_fn=<DivBackward0>)\n",
            "tensor(0.5186, grad_fn=<DivBackward0>)\n",
            "tensor(0.3332, grad_fn=<DivBackward0>)\n",
            "tensor(0.4236, grad_fn=<DivBackward0>)\n",
            "tensor(0.6202, grad_fn=<DivBackward0>)\n",
            "tensor(1.2859, grad_fn=<DivBackward0>)\n",
            "tensor(0.5538, grad_fn=<DivBackward0>)\n",
            "tensor(1.3923, grad_fn=<DivBackward0>)\n",
            "tensor(0.4611, grad_fn=<DivBackward0>)\n",
            "tensor(0.8381, grad_fn=<DivBackward0>)\n",
            "tensor(0.5620, grad_fn=<DivBackward0>)\n",
            "tensor(0.9096, grad_fn=<DivBackward0>)\n",
            "tensor(1.0582, grad_fn=<DivBackward0>)\n",
            "tensor(1.1029, grad_fn=<DivBackward0>)\n",
            "tensor(0.8801, grad_fn=<DivBackward0>)\n",
            "tensor(1.1950, grad_fn=<DivBackward0>)\n",
            "tensor(1.3859, grad_fn=<DivBackward0>)\n",
            "tensor(0.8131, grad_fn=<DivBackward0>)\n",
            "tensor(0.6444, grad_fn=<DivBackward0>)\n",
            "tensor(1.0806, grad_fn=<DivBackward0>)\n",
            "tensor(0.3459, grad_fn=<DivBackward0>)\n",
            "tensor(0.7541, grad_fn=<DivBackward0>)\n",
            "tensor(0.0996, grad_fn=<DivBackward0>)\n",
            "tensor(0.7572, grad_fn=<DivBackward0>)\n",
            "tensor(0.6659, grad_fn=<DivBackward0>)\n",
            "tensor(0.6925, grad_fn=<DivBackward0>)\n",
            "tensor(0.6080, grad_fn=<DivBackward0>)\n",
            "tensor(0.9681, grad_fn=<DivBackward0>)\n",
            "tensor(0.5685, grad_fn=<DivBackward0>)\n",
            "tensor(0.7424, grad_fn=<DivBackward0>)\n",
            "tensor(0.5624, grad_fn=<DivBackward0>)\n",
            "tensor(0.7305, grad_fn=<DivBackward0>)\n",
            "tensor(0.2444, grad_fn=<DivBackward0>)\n",
            "tensor(1.7102, grad_fn=<DivBackward0>)\n",
            "tensor(1.0589, grad_fn=<DivBackward0>)\n",
            "tensor(1.1815, grad_fn=<DivBackward0>)\n",
            "tensor(0.4251, grad_fn=<DivBackward0>)\n",
            "tensor(1.4652, grad_fn=<DivBackward0>)\n",
            "tensor(0.5617, grad_fn=<DivBackward0>)\n",
            "tensor(1.4518, grad_fn=<DivBackward0>)\n",
            "tensor(0.8721, grad_fn=<DivBackward0>)\n",
            "tensor(0.8820, grad_fn=<DivBackward0>)\n",
            "tensor(1.4239, grad_fn=<DivBackward0>)\n",
            "tensor(1.3000, grad_fn=<DivBackward0>)\n",
            "tensor(0.6920, grad_fn=<DivBackward0>)\n",
            "tensor(0.9632, grad_fn=<DivBackward0>)\n",
            "tensor(1.8187, grad_fn=<DivBackward0>)\n",
            "tensor(1.3209, grad_fn=<DivBackward0>)\n",
            "tensor(0.5576, grad_fn=<DivBackward0>)\n",
            "tensor(0.7653, grad_fn=<DivBackward0>)\n",
            "tensor(0.7838, grad_fn=<DivBackward0>)\n",
            "tensor(1.7921, grad_fn=<DivBackward0>)\n",
            "tensor(1.0187, grad_fn=<DivBackward0>)\n",
            "tensor(0.9300, grad_fn=<DivBackward0>)\n",
            "tensor(0.5867, grad_fn=<DivBackward0>)\n",
            "tensor(1.4053, grad_fn=<DivBackward0>)\n",
            "tensor(0.6982, grad_fn=<DivBackward0>)\n",
            "tensor(0.5873, grad_fn=<DivBackward0>)\n",
            "tensor(0.6897, grad_fn=<DivBackward0>)\n",
            "tensor(0.7571, grad_fn=<DivBackward0>)\n",
            "tensor(0.8668, grad_fn=<DivBackward0>)\n",
            "tensor(1.0785, grad_fn=<DivBackward0>)\n",
            "tensor(1.0433, grad_fn=<DivBackward0>)\n",
            "tensor(0.9123, grad_fn=<DivBackward0>)\n",
            "tensor(1.7099, grad_fn=<DivBackward0>)\n",
            "tensor(1.1961, grad_fn=<DivBackward0>)\n",
            "tensor(1.7542, grad_fn=<DivBackward0>)\n",
            "tensor(1.0100, grad_fn=<DivBackward0>)\n",
            "tensor(0.2993, grad_fn=<DivBackward0>)\n",
            "tensor(1.6472, grad_fn=<DivBackward0>)\n",
            "tensor(0.9646, grad_fn=<DivBackward0>)\n",
            "tensor(0.8571, grad_fn=<DivBackward0>)\n",
            "tensor(1.5217, grad_fn=<DivBackward0>)\n",
            "tensor(1.7880, grad_fn=<DivBackward0>)\n",
            "tensor(1.1736, grad_fn=<DivBackward0>)\n",
            "tensor(0.9466, grad_fn=<DivBackward0>)\n",
            "tensor(1.4966, grad_fn=<DivBackward0>)\n",
            "tensor(1.2465, grad_fn=<DivBackward0>)\n",
            "tensor(1.2260, grad_fn=<DivBackward0>)\n",
            "tensor(0.6880, grad_fn=<DivBackward0>)\n",
            "tensor(0.9466, grad_fn=<DivBackward0>)\n",
            "tensor(1.0104, grad_fn=<DivBackward0>)\n",
            "tensor(0.8838, grad_fn=<DivBackward0>)\n",
            "tensor(1.2453, grad_fn=<DivBackward0>)\n",
            "tensor(1.2279, grad_fn=<DivBackward0>)\n",
            "tensor(0.6375, grad_fn=<DivBackward0>)\n",
            "tensor(1.7848, grad_fn=<DivBackward0>)\n",
            "tensor(1.5311, grad_fn=<DivBackward0>)\n",
            "tensor(0.8587, grad_fn=<DivBackward0>)\n",
            "tensor(0.4384, grad_fn=<DivBackward0>)\n",
            "tensor(0.8255, grad_fn=<DivBackward0>)\n",
            "tensor(0.8649, grad_fn=<DivBackward0>)\n",
            "tensor(0.4668, grad_fn=<DivBackward0>)\n",
            "tensor(1.3857, grad_fn=<DivBackward0>)\n",
            "tensor(1.2121, grad_fn=<DivBackward0>)\n",
            "tensor(1.1288, grad_fn=<DivBackward0>)\n",
            "tensor(1.2562, grad_fn=<DivBackward0>)\n",
            "tensor(1.6992, grad_fn=<DivBackward0>)\n",
            "tensor(0.9789, grad_fn=<DivBackward0>)\n",
            "tensor(0.7759, grad_fn=<DivBackward0>)\n",
            "tensor(1.6791, grad_fn=<DivBackward0>)\n",
            "tensor(0.8335, grad_fn=<DivBackward0>)\n",
            "tensor(0.3645, grad_fn=<DivBackward0>)\n",
            "tensor(0.5053, grad_fn=<DivBackward0>)\n",
            "tensor(1.4124, grad_fn=<DivBackward0>)\n",
            "tensor(1.5331, grad_fn=<DivBackward0>)\n",
            "tensor(0.9423, grad_fn=<DivBackward0>)\n",
            "tensor(1.0748, grad_fn=<DivBackward0>)\n",
            "tensor(1.2693, grad_fn=<DivBackward0>)\n",
            "tensor(0.6496, grad_fn=<DivBackward0>)\n",
            "tensor(1.5888, grad_fn=<DivBackward0>)\n",
            "tensor(1.2257, grad_fn=<DivBackward0>)\n",
            "tensor(0.9206, grad_fn=<DivBackward0>)\n",
            "tensor(1.2770, grad_fn=<DivBackward0>)\n",
            "tensor(1.3388, grad_fn=<DivBackward0>)\n",
            "tensor(0.4943, grad_fn=<DivBackward0>)\n",
            "tensor(1.3680, grad_fn=<DivBackward0>)\n",
            "tensor(0.3325, grad_fn=<DivBackward0>)\n",
            "tensor(0.5118, grad_fn=<DivBackward0>)\n",
            "tensor(1.0318, grad_fn=<DivBackward0>)\n",
            "tensor(1.5501, grad_fn=<DivBackward0>)\n",
            "tensor(1.0193, grad_fn=<DivBackward0>)\n",
            "tensor(1.1627, grad_fn=<DivBackward0>)\n",
            "tensor(0.4543, grad_fn=<DivBackward0>)\n",
            "tensor(0.3075, grad_fn=<DivBackward0>)\n",
            "tensor(2.2689, grad_fn=<DivBackward0>)\n",
            "tensor(0.9326, grad_fn=<DivBackward0>)\n",
            "tensor(0.4133, grad_fn=<DivBackward0>)\n",
            "tensor(0.8999, grad_fn=<DivBackward0>)\n",
            "tensor(1.5133, grad_fn=<DivBackward0>)\n",
            "tensor(0.7639, grad_fn=<DivBackward0>)\n",
            "tensor(0.9421, grad_fn=<DivBackward0>)\n",
            "tensor(0.8374, grad_fn=<DivBackward0>)\n",
            "tensor(1.5207, grad_fn=<DivBackward0>)\n",
            "tensor(0.5092, grad_fn=<DivBackward0>)\n",
            "tensor(0.3744, grad_fn=<DivBackward0>)\n",
            "tensor(1.4044, grad_fn=<DivBackward0>)\n",
            "tensor(0.9094, grad_fn=<DivBackward0>)\n",
            "tensor(1.0181, grad_fn=<DivBackward0>)\n",
            "tensor(1.6771, grad_fn=<DivBackward0>)\n",
            "tensor(1.5829, grad_fn=<DivBackward0>)\n",
            "tensor(1.2157, grad_fn=<DivBackward0>)\n",
            "tensor(1.0202, grad_fn=<DivBackward0>)\n",
            "tensor(1.5607, grad_fn=<DivBackward0>)\n",
            "tensor(0.4327, grad_fn=<DivBackward0>)\n",
            "tensor(0.9048, grad_fn=<DivBackward0>)\n",
            "tensor(2.7310, grad_fn=<DivBackward0>)\n",
            "tensor(0.9040, grad_fn=<DivBackward0>)\n",
            "tensor(1.1844, grad_fn=<DivBackward0>)\n",
            "tensor(0.5204, grad_fn=<DivBackward0>)\n",
            "tensor(1.1139, grad_fn=<DivBackward0>)\n",
            "tensor(0.8225, grad_fn=<DivBackward0>)\n",
            "tensor(0.9630, grad_fn=<DivBackward0>)\n",
            "tensor(1.5005, grad_fn=<DivBackward0>)\n",
            "tensor(1.0108, grad_fn=<DivBackward0>)\n",
            "tensor(1.2270, grad_fn=<DivBackward0>)\n",
            "tensor(1.5905, grad_fn=<DivBackward0>)\n",
            "tensor(1.8943, grad_fn=<DivBackward0>)\n",
            "tensor(0.8263, grad_fn=<DivBackward0>)\n",
            "tensor(0.7915, grad_fn=<DivBackward0>)\n",
            "tensor(1.1272, grad_fn=<DivBackward0>)\n",
            "tensor(2.7766, grad_fn=<DivBackward0>)\n",
            "tensor(0.2085, grad_fn=<DivBackward0>)\n",
            "tensor(1.0951, grad_fn=<DivBackward0>)\n",
            "tensor(1.4455, grad_fn=<DivBackward0>)\n",
            "tensor(1.2678, grad_fn=<DivBackward0>)\n",
            "tensor(1.0344, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "tensor(nan, grad_fn=<DivBackward0>)\n",
            "0.0975 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOFUrqP0w4w-",
        "colab_type": "text"
      },
      "source": [
        "## Upto now we were working with the formulas we came up with.\n",
        "## Moving to native Pytorch and fastai tools, along with more involded networks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "960eQL_B0zES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Replacing optimizer with Torch's SGD"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGY_2-0Y04Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear = nn.Linear(28*28, 10)\n",
        "optim = SGD(linear.parameters(), lr)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5ibaTgc1FrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls = DataLoaders(dls, dls_test)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQk7btzG1W4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(dls, linear, loss_func=cross_entropy, opt_func=SGD,\n",
        "                metrics=acc_of_data_)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQvTnoUn1XUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "c7fcad1f-80c8-4208-b660-a055982478ca"
      },
      "source": [
        "learn.fit(10, lr)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>acc_of_data_</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.642563</td>\n",
              "      <td>1.594307</td>\n",
              "      <td>0.742800</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.251247</td>\n",
              "      <td>1.220256</td>\n",
              "      <td>0.803100</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.042122</td>\n",
              "      <td>1.014514</td>\n",
              "      <td>0.827500</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.908192</td>\n",
              "      <td>0.887444</td>\n",
              "      <td>0.838300</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.826135</td>\n",
              "      <td>0.801656</td>\n",
              "      <td>0.845200</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.768344</td>\n",
              "      <td>0.739670</td>\n",
              "      <td>0.851700</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.724449</td>\n",
              "      <td>0.692750</td>\n",
              "      <td>0.857500</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.682744</td>\n",
              "      <td>0.655764</td>\n",
              "      <td>0.862000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.653099</td>\n",
              "      <td>0.625897</td>\n",
              "      <td>0.866200</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.632567</td>\n",
              "      <td>0.601147</td>\n",
              "      <td>0.869500</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtZxYXR5Juw8",
        "colab_type": "text"
      },
      "source": [
        "##With the linear model we are at accuracy of ~87% while training for 10 epochs.\n",
        "\n",
        "### Non let's add some non linearity and See where things go. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9u0__1z1XoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Adding a non linearity\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(28*28,128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128,10))"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do6aAXI-8Tz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner = Learner(dls, model, opt_func=SGD,\n",
        "                loss_func=cross_entropy, metrics=acc_of_data_)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-gkZ3GC8qSE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e07cbce8-5c88-4c79-e2fe-78cb0f2cf111"
      },
      "source": [
        "learner.fit(40, 1e-2)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>acc_of_data_</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.630604</td>\n",
              "      <td>0.598414</td>\n",
              "      <td>0.863800</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.419179</td>\n",
              "      <td>0.409471</td>\n",
              "      <td>0.892300</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.379205</td>\n",
              "      <td>0.352502</td>\n",
              "      <td>0.902400</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.350308</td>\n",
              "      <td>0.324070</td>\n",
              "      <td>0.908000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.310007</td>\n",
              "      <td>0.304977</td>\n",
              "      <td>0.914000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.294519</td>\n",
              "      <td>0.290050</td>\n",
              "      <td>0.919100</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.287073</td>\n",
              "      <td>0.277882</td>\n",
              "      <td>0.922700</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.273293</td>\n",
              "      <td>0.266985</td>\n",
              "      <td>0.925400</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.250893</td>\n",
              "      <td>0.259097</td>\n",
              "      <td>0.929300</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.248909</td>\n",
              "      <td>0.248652</td>\n",
              "      <td>0.930800</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.245099</td>\n",
              "      <td>0.239996</td>\n",
              "      <td>0.932900</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.253955</td>\n",
              "      <td>0.232001</td>\n",
              "      <td>0.934900</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.232764</td>\n",
              "      <td>0.224610</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.216549</td>\n",
              "      <td>0.218287</td>\n",
              "      <td>0.937400</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.233071</td>\n",
              "      <td>0.211198</td>\n",
              "      <td>0.940100</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.216518</td>\n",
              "      <td>0.204188</td>\n",
              "      <td>0.942600</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.194711</td>\n",
              "      <td>0.199471</td>\n",
              "      <td>0.943100</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.197627</td>\n",
              "      <td>0.193225</td>\n",
              "      <td>0.944400</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.196991</td>\n",
              "      <td>0.188538</td>\n",
              "      <td>0.945800</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.181122</td>\n",
              "      <td>0.182677</td>\n",
              "      <td>0.946800</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.181356</td>\n",
              "      <td>0.178094</td>\n",
              "      <td>0.948700</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.177649</td>\n",
              "      <td>0.174499</td>\n",
              "      <td>0.950600</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.165287</td>\n",
              "      <td>0.169409</td>\n",
              "      <td>0.950900</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.171765</td>\n",
              "      <td>0.164744</td>\n",
              "      <td>0.953100</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.173045</td>\n",
              "      <td>0.161896</td>\n",
              "      <td>0.954000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.159468</td>\n",
              "      <td>0.159545</td>\n",
              "      <td>0.954600</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.146906</td>\n",
              "      <td>0.155068</td>\n",
              "      <td>0.956400</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.151799</td>\n",
              "      <td>0.151050</td>\n",
              "      <td>0.957500</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.149300</td>\n",
              "      <td>0.148926</td>\n",
              "      <td>0.957500</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.141366</td>\n",
              "      <td>0.145343</td>\n",
              "      <td>0.958300</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.143040</td>\n",
              "      <td>0.143455</td>\n",
              "      <td>0.958500</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.140750</td>\n",
              "      <td>0.140339</td>\n",
              "      <td>0.959900</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.144173</td>\n",
              "      <td>0.137738</td>\n",
              "      <td>0.960700</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.128048</td>\n",
              "      <td>0.135649</td>\n",
              "      <td>0.961100</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.137264</td>\n",
              "      <td>0.132889</td>\n",
              "      <td>0.962400</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.136370</td>\n",
              "      <td>0.132038</td>\n",
              "      <td>0.962600</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.129540</td>\n",
              "      <td>0.129662</td>\n",
              "      <td>0.962900</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.132557</td>\n",
              "      <td>0.127240</td>\n",
              "      <td>0.963200</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.108042</td>\n",
              "      <td>0.125348</td>\n",
              "      <td>0.963500</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.121266</td>\n",
              "      <td>0.122816</td>\n",
              "      <td>0.965200</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gkqcSzTzBj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f120f02a-43e8-4118-900f-81c4c10e6234"
      },
      "source": [
        "plt.plot((L(learner.recorder.values)).itemgot(2))\n",
        "plt.title('Validation accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\");"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNYtq8I5KHsq",
        "colab_type": "text"
      },
      "source": [
        "### Not too bad Adding one layer of non-linearity and also training for a \n",
        "###substantial epochs got us to ~97%. \n",
        "####Even at 10 epochs it beat the strictly linear model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EqTNlzBCvNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c83a08f7-7b57-4eb5-bf36-da3ba7474664"
      },
      "source": [
        "##Using slightly more involved network ResNet with 18 layers:\n",
        "dls = ImageDataLoaders.from_folder(path, train=\"training\", valid=\"testing\")\n",
        "\n",
        "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
        "                    loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.fit(5, lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.124324</td>\n",
              "      <td>0.214103</td>\n",
              "      <td>0.943700</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.083419</td>\n",
              "      <td>0.065589</td>\n",
              "      <td>0.980300</td>\n",
              "      <td>01:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.062813</td>\n",
              "      <td>0.035140</td>\n",
              "      <td>0.989100</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.046921</td>\n",
              "      <td>0.034787</td>\n",
              "      <td>0.989000</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.037086</td>\n",
              "      <td>0.032392</td>\n",
              "      <td>0.990500</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNy75VbmKdKO",
        "colab_type": "text"
      },
      "source": [
        "###This is the performance for resnet. Quite impressive!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwS8QdrFGXpO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ddedbd33-d167-4728-8f5a-eb45f9cda454"
      },
      "source": [
        "plt.plot(L(learn.recorder.values).itemgot(2))\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Epochs')\n",
        "plt.title(\"Accuracy againt No. Epochs\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUu1lBU2Iukm",
        "colab_type": "text"
      },
      "source": [
        "###Below codes are debugging efforts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scqd0EHOIsSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzAiTQCHGnGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrpBFedvn6qZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63911cf1-3cb8-4edd-bff2-4f85c28020ad"
      },
      "source": [
        "weights, bias = init_params()\n",
        "weights.shape, bias.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784, 10]), torch.Size([10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvpIP9Prog7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3f2e2cda-17f6-4f50-d3fa-11f487b3250c"
      },
      "source": [
        "## Testing with 5 samples from the test set\n",
        "lr = 0.01\n",
        "x = train_x[0:5]\n",
        "y = train_y[0:5]\n",
        "dls_trial = (x,y)\n",
        "preds = linear1(x)\n",
        "preds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([107.6494, 104.4783, 113.6216, 115.1003, 107.9588, 118.6902, 109.3886,\n",
              "        114.7457, 104.3604, 116.9249], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb41-JL0QMeR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b46b0e10-84a0-427a-ae52-6d0800093319"
      },
      "source": [
        "loss = cross_entropy(preds, y)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.5417, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 396
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbopi7MqRyir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Calculating the gradient, adjusting the weights and zeroising the gradients\n",
        "calc_grad_n_step(loss, lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXVgejmxR_89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72e58119-44d8-4202-bc6a-f524711866ee"
      },
      "source": [
        "## Running the cycle again to see if the loss decreases. \n",
        "preds = linear1(x)\n",
        "loss = cross_entropy(preds, y)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.3643, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8691jjIOSnwN",
        "colab_type": "text"
      },
      "source": [
        "##Phew! The loss is lower than before. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMF6-aUXS7Sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "72d6816d-a697-4ebe-f0b8-b9c9d534c03f"
      },
      "source": [
        "## Let's train for 10 epochs and see if the loss keeps decreasing steadily\n",
        "for i in range(10):\n",
        "    lr = 0.01\n",
        "    weights, bias = init_params()\n",
        "    preds = linear1(x)\n",
        "    loss = cross_entropy(preds, y)\n",
        "    calc_grad_n_step(loss, lr)\n",
        "    print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(11.2195, grad_fn=<DivBackward0>)\n",
            "tensor(5.5926, grad_fn=<DivBackward0>)\n",
            "tensor(5.2006, grad_fn=<DivBackward0>)\n",
            "tensor(4.9472, grad_fn=<DivBackward0>)\n",
            "tensor(1.9228, grad_fn=<DivBackward0>)\n",
            "tensor(6.9587, grad_fn=<DivBackward0>)\n",
            "tensor(4.0982, grad_fn=<DivBackward0>)\n",
            "tensor(2.5247, grad_fn=<DivBackward0>)\n",
            "tensor(6.0229, grad_fn=<DivBackward0>)\n",
            "tensor(2.3157, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk-M5Zi7UsXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Creating a function which trains for a given number of times\n",
        "\n",
        "def train_epoch(dls, model, epoch=10, lr=0.1, *args, **kwargs):\n",
        "    for i in range(epoch):\n",
        "        x,y = dls\n",
        "        weights, bias = init_params()\n",
        "        preds = model(x)\n",
        "        loss = cross_entropy(preds, y)\n",
        "        calc_grad_n_step(loss, lr)\n",
        "        if i % 2 == 0: print(loss, end=' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMHk84VfXB2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9c995f92-8306-4f6d-d398-2c65f5fd9593"
      },
      "source": [
        "## Function for training multiple epochs appears to work.\n",
        "train_epoch(dls_trial, linear1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.8981, grad_fn=<DivBackward0>) tensor(0.0276, grad_fn=<DivBackward0>) tensor(0.0148, grad_fn=<DivBackward0>) tensor(0.0105, grad_fn=<DivBackward0>) tensor(0.0083, grad_fn=<DivBackward0>) "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbzl3qBD7gGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f58fd5d-d6e9-4817-ec6c-568199243016"
      },
      "source": [
        "### Accuracy metric\n",
        "preds = linear1(x)\n",
        "probs = soft_max(preds)\n",
        "torch.argmax(probs, dim=1)\n",
        "acc = (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).sum()\n",
        "percent_acc = torch.true_divide(acc, preds.shape[0]) ## Here the accuracy is 100% but that is only with a small sample and trained after 10 epochs\n",
        "percent_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 402
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwFDD7S_cbBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed221acd-1ef5-4a0d-9cb0-9986d895a62b"
      },
      "source": [
        "##Checking the accuracy metric for sanity check with random weights. \n",
        "preds = linear1(x)\n",
        "probs = soft_max(preds)\n",
        "torch.argmax(probs, dim=1)\n",
        "acc = (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).sum()\n",
        "percent_acc = torch.true_divide(acc, preds.shape[0])\n",
        "percent_acc ## Well out target is letter zeros and the accuracy metric is 0% random initialization. Let's see how it does forward."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP3CYSMob051",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Function to check accuracy metric\n",
        "def acc_of_data(dls, model):\n",
        "    x, y = dls \n",
        "    preds = model(x)\n",
        "    probs = soft_max(preds)\n",
        "    acc = (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).sum()\n",
        "    percent_acc = torch.true_divide(acc, preds.shape[0])\n",
        "    print(percent_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAQue493ZRgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbc73e47-26a8-4b94-8b50-579f8f79a142"
      },
      "source": [
        "acc_of_data(dls_trial, linear1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3Kk2X2pjRI2",
        "colab_type": "text"
      },
      "source": [
        "##Need to investigate why the loss is not changing below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98oKEOjaep2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "de1a1311-6cfd-4ce1-e918-8f9b8528034c"
      },
      "source": [
        "## Choosing a random set of data to check to see if the model works\n",
        "## Ran into issues with random indicies, Not sure why. \n",
        "idxs = torch.randint(0, 60000, (100,1))\n",
        "dummy_train, labels = train_x[idxs], train_y[idxs] ## This is the training set\n",
        "train_epoch((x,y), linear1, epoch=20, lr=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0069, grad_fn=<DivBackward0>) tensor(0.0069, grad_fn=<DivBackward0>) tensor(0.0069, grad_fn=<DivBackward0>) tensor(0.0069, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH0L8D0ihLXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "72048974-9976-4b61-d88c-18f3385e1c0a"
      },
      "source": [
        "## Seems to work fine here\n",
        "x_ = train_x[500:1000]\n",
        "y_ = train_y[500:1000]\n",
        "dls_trial_ = (x_,y_)\n",
        "train_epoch(dls_trial_, linear1, epoch=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0315, grad_fn=<DivBackward0>) tensor(0.0283, grad_fn=<DivBackward0>) tensor(0.0256, grad_fn=<DivBackward0>) tensor(0.0233, grad_fn=<DivBackward0>) tensor(0.0214, grad_fn=<DivBackward0>) tensor(0.0198, grad_fn=<DivBackward0>) tensor(0.0183, grad_fn=<DivBackward0>) tensor(0.0171, grad_fn=<DivBackward0>) tensor(0.0160, grad_fn=<DivBackward0>) tensor(0.0151, grad_fn=<DivBackward0>) "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ytZDZIWIiKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2336dd9a-8482-434d-9cd9-3506565ce465"
      },
      "source": [
        "### Debugging step: Writing a function that train one batch and prints the loss\n",
        "\n",
        "def train_once(x,y):\n",
        "    weights, bias = init_params()\n",
        "    for _ in range(5):\n",
        "        preds = linear1(x)\n",
        "        loss = cross_entropy(preds, y)\n",
        "        calc_grad_n_step(loss, lr)\n",
        "        print(loss)\n",
        "train_once(train_x[:5],train_y[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.7491e-05, grad_fn=<DivBackward0>)\n",
            "tensor(2.7491e-05, grad_fn=<DivBackward0>)\n",
            "tensor(2.7491e-05, grad_fn=<DivBackward0>)\n",
            "tensor(2.7491e-05, grad_fn=<DivBackward0>)\n",
            "tensor(2.7491e-05, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hBfZ15DlsxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Same function as above for training but for batches.\n",
        "\n",
        "\n",
        "# def train_batch(dls, model, lr=0.1, *args, **kwargs):\n",
        "#     for x,y in dls:\n",
        "#         weights, bias = init_params()\n",
        "#         preds = model(x)\n",
        "#         loss = cross_entropy(preds, y)\n",
        "#         calc_grad_n_step(loss, lr)\n",
        "#         print(loss)\n",
        "\n",
        "# def train_(epoch, lr):\n",
        "#     for _ in range(epoch):\n",
        "#         train_batch(dls, linear1, lr=lr)\n",
        "#         print(f'Validation accuracy per epoch: {val_epoch(dls_test)}')\n",
        "\n",
        "\n",
        "\n",
        "# def train_batch(dls, model, epoch=10, lr=0.1, print_loss=False, *args, **kwargs):\n",
        "#         for i in range(epoch):\n",
        "#             for batch in dls:\n",
        "#                 x, y = batch\n",
        "#                 lr = lr\n",
        "#                 weights, bias = init_params()\n",
        "#                 preds = model(x)\n",
        "#                 loss = cross_entropy(preds, y)\n",
        "#                 calc_grad_n_step(loss, lr)\n",
        "#                 if print_loss:\n",
        "#                     print(loss, end=' ')\n",
        "\n",
        "## Function for validating the training. Let's see if it was worth it.\n",
        "\n",
        "# def acc_of_data(dls, model):\n",
        "#     x, y = dls \n",
        "#     preds = model(x)\n",
        "#     probs = soft_max(preds)\n",
        "#     return (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).float().mean()\n",
        "\n",
        "\n",
        "# def val_epoch(dls):\n",
        "#     stacked_acc = [acc_of_data(batch, linear1) for batch in dls]\n",
        "#     return torch.stack(stacked_acc).mean()\n",
        "\n",
        "\n",
        "# def val_acc(dls, model):\n",
        "#     cum = 0\n",
        "#     counter = 0\n",
        "#     percent_final = torch.true_divide(cum, counter)\n",
        "#     for batch in dls:\n",
        "#         x, y = batch \n",
        "#         preds = model(x)\n",
        "#         probs = soft_max(preds)\n",
        "#         acc = (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).sum()\n",
        "#         percent_acc = torch.true_divide(acc, preds.shape[0])\n",
        "#         print(percent_acc)\n",
        "#         cum += percent_acc\n",
        "#         counter += 1\n",
        "\n",
        "#     print(f\"Validation accuracy: {percent_final}\")\n",
        "#     print(cum, counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L6Us95alJO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch(dls, linear1, lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RdV-ECvNCq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}