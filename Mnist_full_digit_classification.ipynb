{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist_full_digit_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNOSGT+sBt4nELpRqKulZ9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishandahal/Fun_Projects/blob/master/Mnist_full_digit_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDpllNDaUFbV",
        "colab_type": "text"
      },
      "source": [
        "###Attempting to create a minist digit classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1duvGAmNSrXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f8c3d11-19b6-4bdc-8f3c-fa54e1747750"
      },
      "source": [
        "!pip install fastai --upgrade -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█                               | 10kB 21.3MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 92kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 112kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 153kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 163kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 174kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 184kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 194kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 204kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 215kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 225kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 235kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 245kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 256kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 266kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 276kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 296kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 307kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 317kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 327kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 337kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 348kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 4.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhYF44fCSgUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fastai\n",
        "from fastai.vision.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRqvgJ9gTAII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "10ed0432-582a-4fd0-9353-d7d97fee71a3"
      },
      "source": [
        "path = untar_data(URLs.MNIST)\n",
        "Path.BASE_PATH = path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMj_U-6zUWPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c472d241-b493-4fb4-83b2-62af5b0e1e98"
      },
      "source": [
        "#Checking the contents of the dataset\n",
        "path.ls()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('training'),Path('testing')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni0GyJ5xcTf8",
        "colab_type": "text"
      },
      "source": [
        "###Lesson learned object needs to be modified by .ls() for it to be iterable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRx2L5mvUnvM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0f8cc85d-1684-45e8-c18d-33b22f7e7983"
      },
      "source": [
        "#Looking at the training set only\n",
        "train_set = (path / 'training').ls().sorted()\n",
        "train_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('training/0'),Path('training/1'),Path('training/2'),Path('training/3'),Path('training/4'),Path('training/5'),Path('training/6'),Path('training/7'),Path('training/8'),Path('training/9')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXZjkZ8XaXn2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "694df1a9-97d6-400e-d3b3-351912b60d56"
      },
      "source": [
        "train_set[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('training/0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNapAlwQU5KR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a3708d96-73e9-49b9-f6bd-670c144f9e11"
      },
      "source": [
        "#Let's see what the digits look like. Just the 9s.\n",
        "sample_nines = train_set[9].ls()\n",
        "sample_nines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#5949) [Path('training/9/17107.png'),Path('training/9/41306.png'),Path('training/9/52315.png'),Path('training/9/46435.png'),Path('training/9/20333.png'),Path('training/9/31659.png'),Path('training/9/25828.png'),Path('training/9/27128.png'),Path('training/9/43324.png'),Path('training/9/3913.png')...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4lv57JfVj9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "outputId": "33a33665-c128-47f1-89bd-674ea3232e57"
      },
      "source": [
        "view_nine = Image.open(sample_nines[9])\n",
        "view_nine"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA00lEQVR4nGNgGLqARbPu1b9/bljl2Dr//vv79+9erHIFf/8++Pv37zsscrLnPk7M55HXe52JRfL237MMDAwMDPd0MeUC/m8zZ2BgYOBYfwbuPrjkt/+X3jX/b3Ds0fuGxdh/f9/9fXfp79+/eTARJoSk+knmC7/PbWBgOILNK4LSLCqsZ//2M2KTZGBgYEj991wEl5zyq7+luOQYKv5d4cQlp/L2XzUuObnzf9+z4JJU+/LAG5cc3/m/S3DJiR/4e04cl+TFv+ckcMkx/HuJUx/JAADZTk50MaRAowAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FE5C167BEB8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8a7iXH8hrWn",
        "colab_type": "text"
      },
      "source": [
        "###Converting images into tensors and stacking them together in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymm2bjLpi8I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zeros = train_set[0].ls().sorted()\n",
        "ones = train_set[1].ls().sorted()\n",
        "zeros = train_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtnU-uqUj1jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Function to create a dictionary of all the images into their respective named containers\n",
        "def dict_for_digits(path):\n",
        "    str_ = (0,1,2,3,4,5,6,7,8,9)\n",
        "    new_dict = {str_[idx]: letters.ls() for idx, letters in enumerate(path)}\n",
        "    return new_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NysafyIx5yMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dcc0d463-4ede-47fd-eb38-e2163cbfe2b2"
      },
      "source": [
        "##Going to get the test set ready while here\n",
        "test_set = path / 'testing'\n",
        "test_set = test_set.ls().sorted()\n",
        "test_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('testing/0'),Path('testing/1'),Path('testing/2'),Path('testing/3'),Path('testing/4'),Path('testing/5'),Path('testing/6'),Path('testing/7'),Path('testing/8'),Path('testing/9')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tigl6Td26Ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digit_dict_train = dict_for_digits(train_set)\n",
        "digit_dict_test = dict_for_digits(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFehcZDV6s7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "3dad0b84-a682-4b14-bc1d-c2b92e0ba146"
      },
      "source": [
        "digit_dict_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: (#5923) [Path('training/0/52804.png'),Path('training/0/27283.png'),Path('training/0/9966.png'),Path('training/0/33214.png'),Path('training/0/19303.png'),Path('training/0/4488.png'),Path('training/0/43613.png'),Path('training/0/4926.png'),Path('training/0/5844.png'),Path('training/0/41358.png')...],\n",
              " 1: (#6742) [Path('training/1/49392.png'),Path('training/1/26745.png'),Path('training/1/8648.png'),Path('training/1/53206.png'),Path('training/1/27789.png'),Path('training/1/49308.png'),Path('training/1/18852.png'),Path('training/1/5966.png'),Path('training/1/27657.png'),Path('training/1/8625.png')...],\n",
              " 2: (#5958) [Path('training/2/1662.png'),Path('training/2/21623.png'),Path('training/2/472.png'),Path('training/2/55508.png'),Path('training/2/47369.png'),Path('training/2/5318.png'),Path('training/2/54052.png'),Path('training/2/44934.png'),Path('training/2/5129.png'),Path('training/2/48986.png')...],\n",
              " 3: (#6131) [Path('training/3/40940.png'),Path('training/3/55876.png'),Path('training/3/27726.png'),Path('training/3/20675.png'),Path('training/3/17967.png'),Path('training/3/22619.png'),Path('training/3/24867.png'),Path('training/3/23747.png'),Path('training/3/58881.png'),Path('training/3/17403.png')...],\n",
              " 4: (#5842) [Path('training/4/15942.png'),Path('training/4/23596.png'),Path('training/4/11255.png'),Path('training/4/11460.png'),Path('training/4/45184.png'),Path('training/4/12285.png'),Path('training/4/40334.png'),Path('training/4/36909.png'),Path('training/4/9496.png'),Path('training/4/41528.png')...],\n",
              " 5: (#5421) [Path('training/5/23200.png'),Path('training/5/12829.png'),Path('training/5/11359.png'),Path('training/5/51298.png'),Path('training/5/54189.png'),Path('training/5/24077.png'),Path('training/5/49928.png'),Path('training/5/31772.png'),Path('training/5/43882.png'),Path('training/5/26404.png')...],\n",
              " 6: (#5918) [Path('training/6/11832.png'),Path('training/6/16425.png'),Path('training/6/15708.png'),Path('training/6/26114.png'),Path('training/6/35213.png'),Path('training/6/23569.png'),Path('training/6/1020.png'),Path('training/6/57891.png'),Path('training/6/45080.png'),Path('training/6/57881.png')...],\n",
              " 7: (#6265) [Path('training/7/27392.png'),Path('training/7/26255.png'),Path('training/7/42265.png'),Path('training/7/46053.png'),Path('training/7/54638.png'),Path('training/7/22754.png'),Path('training/7/36611.png'),Path('training/7/8805.png'),Path('training/7/4832.png'),Path('training/7/10002.png')...],\n",
              " 8: (#5851) [Path('training/8/7872.png'),Path('training/8/16467.png'),Path('training/8/6792.png'),Path('training/8/40945.png'),Path('training/8/37715.png'),Path('training/8/40453.png'),Path('training/8/4021.png'),Path('training/8/20315.png'),Path('training/8/4139.png'),Path('training/8/13436.png')...],\n",
              " 9: (#5949) [Path('training/9/17107.png'),Path('training/9/41306.png'),Path('training/9/52315.png'),Path('training/9/46435.png'),Path('training/9/20333.png'),Path('training/9/31659.png'),Path('training/9/25828.png'),Path('training/9/27128.png'),Path('training/9/43324.png'),Path('training/9/3913.png')...]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf9E1MWI7lxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing tensor conversion before creating a function\n",
        "tensor(Image.open(digit_dict_train[0][0]))\n",
        "tnsr_0 = torch.stack([tensor(Image.open(o)) for o in digit_dict_train[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH9oeqyhBWm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8fc825ab-2235-4a9c-93e9-a13054e95a21"
      },
      "source": [
        "tnsr_0.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5923, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJrP31pP31X4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Converting images into tensors and stacking\n",
        "## Function that converts one folder of images to tensors\n",
        "\n",
        "def img_to_tnsr(folder):\n",
        "    \"\"\"Converts iterable images into tensors and stacks them\"\"\"\n",
        "    return torch.stack([tensor(Image.open(i)) for i in folder]).float() / 255.0\n",
        "\n",
        "def agg_tnsr_imgs(dicts):\n",
        "    \"\"\"Takes in dictionary of images and converts to stacked tensors\"\"\"\n",
        "    tnsr_folder = [img_to_tnsr(dicts[key]) for key, value in dicts.items()]\n",
        "    agged_tnsrs = torch.cat(tnsr_folder[:])\n",
        "    return agged_tnsrs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNcHYSZxd8UQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Creating one hot encoded vectors (labels) for the dataset\n",
        "## Using the dictionary as a guide\n",
        "def one_hot_label(rows, cols, index):\n",
        "\n",
        "    shape_of_vector = torch.zeros([rows,cols])\n",
        "    shape_of_vector[:, index] = 1\n",
        "    return shape_of_vector\n",
        "\n",
        "def label_all(dicts):\n",
        "    labels = [one_hot_label(len(values), len(dicts.keys()), keys) for keys,values in dicts.items()]\n",
        "    labels = torch.cat(labels[:])\n",
        "    return labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOhaolLgieaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training and test set with all the images converted to tensor, stacked and concatenated\n",
        "train_x = agg_tnsr_imgs(digit_dict_train)\n",
        "test_x = agg_tnsr_imgs(digit_dict_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfxV4PFFieOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b533a02d-4471-4e33-cf7f-0c0951317dfb"
      },
      "source": [
        "show_image(test_x[1500]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADb0lEQVR4nO2cu29jRRSHv5n7Sq5jO08H5aUoEloKCoREQQENoqKh4f+j50+gQKJCWiEFIVBYsWTFQsLm4Udsx9d3fGcoopBktGxHzhWer7SL+enTmTl3zrWsnHME7tDSAepGEOIRhHgEIR5BiEf8pi8/1V/8b1vQ1/Yr9brPQ4V4BCEeQYhHEOIRhHgEIR5vbLuPSby7g9lZIx5MUMNrbH+AHQ4fP8ejr/gvnH62S/75K05/7tB+tkbnaRu+/+nRc9Rqy1ROoWeKuAA1syIZ6iFEKRa7jle/rdP6FVaOxuiznkgUcSFRq0W8t8NoS7O826dsqZvqEBpciQtxe1v0Ptym+njAN+9/yehtg9MK1GuvGv854kLQ4DQkUcWSykhaJdfbOa7ZkIojjAVlwbqbijjYvOD8vYhyuy0SR16IR+U0qgJl5/QM8bk2CfE1qHJO227VzJisa9qLBQBpVFFl4GKZaOJCytWU4b5lv3UJQDOdMms6qmxOhTil4F6H1Tgk55biQupG7YScjFo0ThTJVSmyfu2EXHaXWPmlJD6/Elm/dkKsiYjHMzAzkfVrJwSjiMYGZ4zI8vUTIkwQ4hGEeAQhHuJCbKKoFi0jk/F06kh6MdF5Hzcai+QRn7q7CEgtY5NxWOyRDBTV+QVuXtvuZFXz5OCUzfyK50WHuOBGhpvT63/ZUnzSOWIjHXFatNFTwFbzN2TWjQbxzjbFuuOj/Bld0+C7F/ssdmUq459cUgurPMeuNpm1K95NDUOTwckC6VUlFQmQ3DJagdagHZlKiLVsZdwieobcDoc0Ci06FrpDTIi7nhBdDIj7MT+Whu40l4ryALkKMQY3maCn8GfVppgl4GTe1t1H7MFMr69R7m9QvjXjg+ySSFvSK0VUzGmXcfkCxUZG0pzSiRpYp4gmoMs57TKm06T7TkSzUXA4nfLi+SZb3w5Jj8+kIgGCW6bKY8plx3Iy46xaIulHRMd/Yccyl7pbxC93hYl5adaIxwrbH+Aq2S0jLsRazdAuoGbgjMyrh/uIX+7Gk5QfhrvEE+kkN8hd7owlKhRmmHHU65CM6/GkKrZl0sNjDv5YwWUpNs+JT35HZiT0ELku0+tB7+6XhnWQATU4Q+pGEOIRhHgEIR5BiEcQ4qHCnyE8JFSIRxDiEYR4BCEeQYhHEOLxN6tPLD2W5mBtAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc6zV3esieDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "937a3c7c-c4ed-4e7d-b72c-dc160e954026"
      },
      "source": [
        "##Checking the data type \n",
        "train_x.dtype, test_x.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En1GGXFl5aro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0059a5b-9d84-4044-83c1-eb1575c29c3c"
      },
      "source": [
        "train_x.shape, test_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSs8k5Wk_Gug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Creating training and testing labels\n",
        "train_y = label_all(digit_dict_train)\n",
        "test_y = label_all(digit_dict_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB31JuHTfr21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "757d4dbf-a163-439d-c556-235657b42a13"
      },
      "source": [
        "train_y.shape, test_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 10]), torch.Size([10000, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xxXw0eHcSzX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b472aed7-b7a6-4ac5-f8bd-1c986c0c86b4"
      },
      "source": [
        "train_x.shape, test_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ilfk212ciuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Flattening the inputs for test and training set\n",
        "## Adding an extra rank for the linear model computation\n",
        "train_x = train_x.view(-1, 28*28)\n",
        "test_x = test_x.view(-1, 28*28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAj0QSQVdBmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b546a5d-1352-4eed-a43e-4d5adc39c84b"
      },
      "source": [
        "# train_x[0].shape, test_x[0].shape\n",
        "train_x.shape, test_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 784]), torch.Size([10000, 784]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8stzPgY9dXyG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e64f9f9-4959-4a4d-ac84-793929390702"
      },
      "source": [
        "## Collating training inputs and labels\n",
        "dset = list(zip(train_x, train_y))\n",
        "x, y = dset[0]\n",
        "x.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), torch.Size([10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv6hAu15fCY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3ae6bfe-1a15-4970-c4d2-1081ca8bc9c4"
      },
      "source": [
        "#Preparing the Test set\n",
        "dset_test = list(zip(test_x, test_y))\n",
        "x, y = dset_test[0]\n",
        "x.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), torch.Size([10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qo2MBKzjnCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Creating dataloader with the training set and test set\n",
        "dls = DataLoader(dset, bs=64, shuffle=True)\n",
        "dls_test = DataLoader(dset_test, bs=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWhHyzelgWPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "69ab1be2-e71d-4a65-e46b-cc228e46eed3"
      },
      "source": [
        "x, y = dls.one_batch()\n",
        "x.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 784]), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOZYWliYnDwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Initializing parameters(weights and biases)\n",
        "def init_params():\n",
        "    return torch.rand(28*28, 10).requires_grad_() , torch.rand(10).requires_grad_()\n",
        "\n",
        "#Simple one layer Linear Model \n",
        "def linear1(input):\n",
        "    #input dimension n,28*28\n",
        "    #weight dimension 28*28, 10\n",
        "    #bias dimension 10, 1\n",
        "    #output dimension n,10\n",
        "    return input @ weights + bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtESf5HEgFoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Loss function \n",
        "## Going to need cross entropy loss function\n",
        "## Had a tough time implementing softmax on torch. Kept running into numerical\n",
        "## Solution is to remove subtract max from numerator\n",
        "# instability on the first row which threw made loss function nan. \n",
        "def soft_max(preds):\n",
        "    \"Takes predictions from the final layer and return probabilities\"\n",
        "    # return torch.exp(preds) / torch.sum(torch.exp(preds), dim=1).view(-1,1)\n",
        "    return preds.softmax(dim=1)\n",
        "    # return exp(preds) / exp(preds).sum(dim=0, keepdim=True) #Applying softmax to get probabilities\n",
        "\n",
        "\n",
        "def neg_log_like(preds, targs):\n",
        "    \"Takes the probabilities from softmax and returns average loss\"\n",
        "    return -(preds.log() * targs).sum() / len(preds)\n",
        "\n",
        "\n",
        "def cross_entropy(preds, targs):\n",
        "    \"Putting softmax and neg-log together\"\n",
        "    soft = soft_max(preds)\n",
        "    return neg_log_like(soft, targs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU9-TBbrh4zx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11635ab8-cd1f-43ed-c83c-2f05f18e90e2"
      },
      "source": [
        "## Performing a simple forward pass.\n",
        "images, label = dls.one_batch()\n",
        "weights, bias = init_params()\n",
        "preds = linear1(images)\n",
        "loss = cross_entropy(preds, label)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.7432, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF8WiiOhix40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrlCMoIWi8Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-3\n",
        "weights.data -= lr * weights.grad\n",
        "bias.data -= lr * bias.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkIFvI4AjWL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights.grad = None\n",
        "bias.grad = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zJc6EmCjY15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4d2545a-83e8-407b-9876-ae2655c9f3fd"
      },
      "source": [
        "## Checking to see if the loss decreased.\n",
        "preds = linear1(images)\n",
        "loss = cross_entropy(preds, label)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.7385, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RztKZ4Tr_KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Calculating the gradient, taking the step and zeroizing the gradient\n",
        "\n",
        "def calc_grad_n_step(loss_, lr):\n",
        "    loss_.backward()\n",
        "    weights.data -= lr * weights.grad\n",
        "    bias.data -= lr * bias.grad\n",
        "    weights.grad, bias.grad = None, None\n",
        "\n",
        "def train_batch(lr):\n",
        "    for x,y in dls:\n",
        "        preds = linear1(x)\n",
        "        loss = cross_entropy(preds, y)\n",
        "        calc_grad_n_step(loss, lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huviVoj1mBzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Calculating accuracy\n",
        "def acc_of_data(dls, model):\n",
        "    x, y = dls \n",
        "    preds = model(x)\n",
        "    probs = soft_max(preds)\n",
        "    return (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).float().mean()\n",
        "\n",
        "\n",
        "def val_epoch(dls):\n",
        "    stacked_acc = [acc_of_data(batch, linear1) for batch in dls]\n",
        "    return torch.stack(stacked_acc).mean()\n",
        "\n",
        "## generic accuracy calculator from predictions and targets\n",
        "def cal_accuracy(preds, y):\n",
        "    probs = soft_max(preds)\n",
        "    return (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).float().mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXDe8fxC7IaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Alternate accuracy metric\n",
        "def acc_of_data_(preds, targs):\n",
        "    probs = soft_max(preds)\n",
        "    return (torch.argmax(probs, dim=1) == torch.argmax(targs, dim=1)).float().mean()\n",
        "\n",
        "\n",
        "def val_epoch_(dls):\n",
        "    stacked_acc = [acc_of_data(linear1(x), y) for x,y in dls]\n",
        "    return torch.stack(stacked_acc).mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U_JtivdmOMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e86a1a4-abf6-4925-a4de-f7af27ddd91a"
      },
      "source": [
        "val_epoch(dls_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0725)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfp7eu5Gnkro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8b571636-8215-437a-9337-ff130bb8128c"
      },
      "source": [
        "for _ in range(40):\n",
        "    train_batch(lr=lr)\n",
        "    print(f'{val_epoch(dls_test):.4f}', end=' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2052 0.3306 0.4396 0.5140 0.5749 0.6173 0.6455 0.6730 0.6957 0.7143 0.7285 0.7433 0.7531 0.7629 0.7708 0.7763 0.7835 0.7910 0.7971 0.8022 0.8050 0.8079 0.8108 0.8151 0.8187 0.8208 0.8236 0.8268 0.8302 0.8326 0.8347 0.8377 0.8405 0.8420 0.8439 0.8455 0.8468 0.8481 0.8501 0.8507 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GMbMVhLo-HO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Creating an optimizer\n",
        "class Optim():\n",
        "    def __init__(self, params, lr):\n",
        "        self.params = list(params)\n",
        "        self.lr = lr\n",
        "    \n",
        "    def step(self):\n",
        "        for p in self.params:\n",
        "            p.data -= p.grad * self.lr\n",
        "    \n",
        "    def zero_grad(self):\n",
        "        for p in self.params:\n",
        "            p.grad = None\n",
        "\n",
        "def calc_grad(x, y, model):\n",
        "        preds = model(x)\n",
        "        loss = cross_entropy(preds, y)\n",
        "        loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_dIDItLtA3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights, bias = init_params()\n",
        "optim = Optim((weights, bias), lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu1Ru5tGtfXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### New modified training epoch func\n",
        "def train_epoch(model, optim):\n",
        "    for images, labels in dls:\n",
        "        calc_grad(images, labels, linear1)\n",
        "        optim.step()\n",
        "        optim.zero_grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQo38N-dus7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fab7fae2-c6f5-467d-cda6-f2810d7c576b"
      },
      "source": [
        "## Not sure what the issue is here\n",
        "for _ in range(10):\n",
        "        train_epoch(linear1, optim)\n",
        "        print(f'{val_epoch(dls_test):.4f}', end=' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0975 0.0975 0.0975 0.0975 0.0975 0.0975 0.0975 0.0975 0.0975 0.0975 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "960eQL_B0zES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Replacing optimizer with Torch's SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGY_2-0Y04Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear = nn.Linear(28*28, 10)\n",
        "optim = SGD(linear.parameters(), lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5ibaTgc1FrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls = DataLoaders(dls, dls_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQk7btzG1W4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(dls, linear, loss_func=cross_entropy, opt_func=SGD,\n",
        "                metrics=acc_of_data_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQvTnoUn1XUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "13e0f1cc-cabf-430e-eee1-5e3dbe404be1"
      },
      "source": [
        "learn.fit(10, lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>acc_of_data_</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.606853</td>\n",
              "      <td>1.559366</td>\n",
              "      <td>0.758500</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.240666</td>\n",
              "      <td>1.199123</td>\n",
              "      <td>0.811100</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.034508</td>\n",
              "      <td>1.000841</td>\n",
              "      <td>0.830500</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.919014</td>\n",
              "      <td>0.878384</td>\n",
              "      <td>0.840200</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.818620</td>\n",
              "      <td>0.795141</td>\n",
              "      <td>0.848400</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.758397</td>\n",
              "      <td>0.734892</td>\n",
              "      <td>0.855200</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.713725</td>\n",
              "      <td>0.689127</td>\n",
              "      <td>0.859500</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.668757</td>\n",
              "      <td>0.653055</td>\n",
              "      <td>0.864200</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.652285</td>\n",
              "      <td>0.623732</td>\n",
              "      <td>0.867300</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.628114</td>\n",
              "      <td>0.599347</td>\n",
              "      <td>0.869100</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtZxYXR5Juw8",
        "colab_type": "text"
      },
      "source": [
        "##With the linear model we are at accuracy of ~87% while training for 10 epochs.\n",
        "\n",
        "### Non let's add some non linearity and See where things go. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9u0__1z1XoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Adding a non linearity\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(28*28,128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do6aAXI-8Tz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(dls, model, opt_func=SGD,\n",
        "                loss_func=cross_entropy, metrics=acc_of_data_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-gkZ3GC8qSE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "876cb83a-651e-4e92-b9ca-ce70f4c2b065"
      },
      "source": [
        "learn.fit(40, 1e-2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>acc_of_data_</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.641221</td>\n",
              "      <td>0.585679</td>\n",
              "      <td>0.863900</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.420750</td>\n",
              "      <td>0.405148</td>\n",
              "      <td>0.892900</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.373352</td>\n",
              "      <td>0.352854</td>\n",
              "      <td>0.900100</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.334767</td>\n",
              "      <td>0.324477</td>\n",
              "      <td>0.909200</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.312967</td>\n",
              "      <td>0.307646</td>\n",
              "      <td>0.913500</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.319067</td>\n",
              "      <td>0.296334</td>\n",
              "      <td>0.917100</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.314760</td>\n",
              "      <td>0.283146</td>\n",
              "      <td>0.920700</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.277917</td>\n",
              "      <td>0.272418</td>\n",
              "      <td>0.922700</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.279553</td>\n",
              "      <td>0.262221</td>\n",
              "      <td>0.925800</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.259488</td>\n",
              "      <td>0.253598</td>\n",
              "      <td>0.928000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.258597</td>\n",
              "      <td>0.246007</td>\n",
              "      <td>0.929200</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.237525</td>\n",
              "      <td>0.238188</td>\n",
              "      <td>0.931400</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.241161</td>\n",
              "      <td>0.230304</td>\n",
              "      <td>0.934300</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.232348</td>\n",
              "      <td>0.224503</td>\n",
              "      <td>0.936200</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.228689</td>\n",
              "      <td>0.219415</td>\n",
              "      <td>0.937300</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.220468</td>\n",
              "      <td>0.211712</td>\n",
              "      <td>0.940200</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.203766</td>\n",
              "      <td>0.206792</td>\n",
              "      <td>0.941000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.198075</td>\n",
              "      <td>0.200487</td>\n",
              "      <td>0.943300</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.185696</td>\n",
              "      <td>0.195728</td>\n",
              "      <td>0.944700</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.176448</td>\n",
              "      <td>0.192709</td>\n",
              "      <td>0.944500</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.185149</td>\n",
              "      <td>0.186709</td>\n",
              "      <td>0.946900</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.183461</td>\n",
              "      <td>0.182889</td>\n",
              "      <td>0.947200</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.180863</td>\n",
              "      <td>0.178151</td>\n",
              "      <td>0.948100</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.186342</td>\n",
              "      <td>0.174250</td>\n",
              "      <td>0.950400</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.166870</td>\n",
              "      <td>0.169995</td>\n",
              "      <td>0.951000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.172328</td>\n",
              "      <td>0.166603</td>\n",
              "      <td>0.952000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.167745</td>\n",
              "      <td>0.163390</td>\n",
              "      <td>0.952800</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.165519</td>\n",
              "      <td>0.160063</td>\n",
              "      <td>0.953300</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.155043</td>\n",
              "      <td>0.156852</td>\n",
              "      <td>0.953600</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.152368</td>\n",
              "      <td>0.153791</td>\n",
              "      <td>0.954300</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.143367</td>\n",
              "      <td>0.151275</td>\n",
              "      <td>0.955100</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.137137</td>\n",
              "      <td>0.148449</td>\n",
              "      <td>0.955400</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.147566</td>\n",
              "      <td>0.145869</td>\n",
              "      <td>0.956100</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.140979</td>\n",
              "      <td>0.143536</td>\n",
              "      <td>0.957000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.144967</td>\n",
              "      <td>0.142101</td>\n",
              "      <td>0.958000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.120876</td>\n",
              "      <td>0.138462</td>\n",
              "      <td>0.958800</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.126703</td>\n",
              "      <td>0.135696</td>\n",
              "      <td>0.959500</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.134561</td>\n",
              "      <td>0.133230</td>\n",
              "      <td>0.961000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.132391</td>\n",
              "      <td>0.132427</td>\n",
              "      <td>0.961200</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.125709</td>\n",
              "      <td>0.130217</td>\n",
              "      <td>0.961100</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNYtq8I5KHsq",
        "colab_type": "text"
      },
      "source": [
        "### Not too bad Adding one layer of non-linearity and also training for a \n",
        "###substantial epochs got us to ~97%. \n",
        "####Even at 10 epochs it beat the strictly linear model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EqTNlzBCvNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c83a08f7-7b57-4eb5-bf36-da3ba7474664"
      },
      "source": [
        "##Using slightly more involved network ResNet with 18 layers:\n",
        "dls = ImageDataLoaders.from_folder(path, train=\"training\", valid=\"testing\")\n",
        "\n",
        "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
        "                    loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.fit(5, lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.124324</td>\n",
              "      <td>0.214103</td>\n",
              "      <td>0.943700</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.083419</td>\n",
              "      <td>0.065589</td>\n",
              "      <td>0.980300</td>\n",
              "      <td>01:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.062813</td>\n",
              "      <td>0.035140</td>\n",
              "      <td>0.989100</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.046921</td>\n",
              "      <td>0.034787</td>\n",
              "      <td>0.989000</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.037086</td>\n",
              "      <td>0.032392</td>\n",
              "      <td>0.990500</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNy75VbmKdKO",
        "colab_type": "text"
      },
      "source": [
        "###This is the performance for resnet. Quite impressive!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwS8QdrFGXpO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ddedbd33-d167-4728-8f5a-eb45f9cda454"
      },
      "source": [
        "plt.plot(L(learn.recorder.values).itemgot(2))\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Epochs')\n",
        "plt.title(\"Accuracy againt No. Epochs\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUu1lBU2Iukm",
        "colab_type": "text"
      },
      "source": [
        "###Below codes are debugging efforts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Scqd0EHOIsSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzAiTQCHGnGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrpBFedvn6qZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63911cf1-3cb8-4edd-bff2-4f85c28020ad"
      },
      "source": [
        "weights, bias = init_params()\n",
        "weights.shape, bias.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784, 10]), torch.Size([10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvpIP9Prog7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3f2e2cda-17f6-4f50-d3fa-11f487b3250c"
      },
      "source": [
        "## Testing with 5 samples from the test set\n",
        "lr = 0.01\n",
        "x = train_x[0:5]\n",
        "y = train_y[0:5]\n",
        "dls_trial = (x,y)\n",
        "preds = linear1(x)\n",
        "preds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([107.6494, 104.4783, 113.6216, 115.1003, 107.9588, 118.6902, 109.3886,\n",
              "        114.7457, 104.3604, 116.9249], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb41-JL0QMeR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b46b0e10-84a0-427a-ae52-6d0800093319"
      },
      "source": [
        "loss = cross_entropy(preds, y)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.5417, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 396
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbopi7MqRyir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Calculating the gradient, adjusting the weights and zeroising the gradients\n",
        "calc_grad_n_step(loss, lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXVgejmxR_89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72e58119-44d8-4202-bc6a-f524711866ee"
      },
      "source": [
        "## Running the cycle again to see if the loss decreases. \n",
        "preds = linear1(x)\n",
        "loss = cross_entropy(preds, y)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.3643, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8691jjIOSnwN",
        "colab_type": "text"
      },
      "source": [
        "##Phew! The loss is lower than before. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMF6-aUXS7Sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "72d6816d-a697-4ebe-f0b8-b9c9d534c03f"
      },
      "source": [
        "## Let's train for 10 epochs and see if the loss keeps decreasing steadily\n",
        "for i in range(10):\n",
        "    lr = 0.01\n",
        "    weights, bias = init_params()\n",
        "    preds = linear1(x)\n",
        "    loss = cross_entropy(preds, y)\n",
        "    calc_grad_n_step(loss, lr)\n",
        "    print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(11.2195, grad_fn=<DivBackward0>)\n",
            "tensor(5.5926, grad_fn=<DivBackward0>)\n",
            "tensor(5.2006, grad_fn=<DivBackward0>)\n",
            "tensor(4.9472, grad_fn=<DivBackward0>)\n",
            "tensor(1.9228, grad_fn=<DivBackward0>)\n",
            "tensor(6.9587, grad_fn=<DivBackward0>)\n",
            "tensor(4.0982, grad_fn=<DivBackward0>)\n",
            "tensor(2.5247, grad_fn=<DivBackward0>)\n",
            "tensor(6.0229, grad_fn=<DivBackward0>)\n",
            "tensor(2.3157, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk-M5Zi7UsXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Creating a function which trains for a given number of times\n",
        "\n",
        "def train_epoch(dls, model, epoch=10, lr=0.1, *args, **kwargs):\n",
        "    for i in range(epoch):\n",
        "        x,y = dls\n",
        "        weights, bias = init_params()\n",
        "        preds = model(x)\n",
        "        loss = cross_entropy(preds, y)\n",
        "        calc_grad_n_step(loss, lr)\n",
        "        if i % 2 == 0: print(loss, end=' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMHk84VfXB2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9c995f92-8306-4f6d-d398-2c65f5fd9593"
      },
      "source": [
        "## Function for training multiple epochs appears to work.\n",
        "train_epoch(dls_trial, linear1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.8981, grad_fn=<DivBackward0>) tensor(0.0276, grad_fn=<DivBackward0>) tensor(0.0148, grad_fn=<DivBackward0>) tensor(0.0105, grad_fn=<DivBackward0>) tensor(0.0083, grad_fn=<DivBackward0>) "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbzl3qBD7gGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f58fd5d-d6e9-4817-ec6c-568199243016"
      },
      "source": [
        "### Accuracy metric\n",
        "preds = linear1(x)\n",
        "probs = soft_max(preds)\n",
        "torch.argmax(probs, dim=1)\n",
        "acc = (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).sum()\n",
        "percent_acc = torch.true_divide(acc, preds.shape[0]) ## Here the accuracy is 100% but that is only with a small sample and trained after 10 epochs\n",
        "percent_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 402
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwFDD7S_cbBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed221acd-1ef5-4a0d-9cb0-9986d895a62b"
      },
      "source": [
        "##Checking the accuracy metric for sanity check with random weights. \n",
        "preds = linear1(x)\n",
        "probs = soft_max(preds)\n",
        "torch.argmax(probs, dim=1)\n",
        "acc = (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).sum()\n",
        "percent_acc = torch.true_divide(acc, preds.shape[0])\n",
        "percent_acc ## Well out target is letter zeros and the accuracy metric is 0% random initialization. Let's see how it does forward."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 403
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP3CYSMob051",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Function to check accuracy metric\n",
        "def acc_of_data(dls, model):\n",
        "    x, y = dls \n",
        "    preds = model(x)\n",
        "    probs = soft_max(preds)\n",
        "    acc = (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).sum()\n",
        "    percent_acc = torch.true_divide(acc, preds.shape[0])\n",
        "    print(percent_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAQue493ZRgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbc73e47-26a8-4b94-8b50-579f8f79a142"
      },
      "source": [
        "acc_of_data(dls_trial, linear1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3Kk2X2pjRI2",
        "colab_type": "text"
      },
      "source": [
        "##Need to investigate why the loss is not changing below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98oKEOjaep2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "de1a1311-6cfd-4ce1-e918-8f9b8528034c"
      },
      "source": [
        "## Choosing a random set of data to check to see if the model works\n",
        "## Ran into issues with random indicies, Not sure why. \n",
        "idxs = torch.randint(0, 60000, (100,1))\n",
        "dummy_train, labels = train_x[idxs], train_y[idxs] ## This is the training set\n",
        "train_epoch((x,y), linear1, epoch=20, lr=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0069, grad_fn=<DivBackward0>) tensor(0.0069, grad_fn=<DivBackward0>) tensor(0.0069, grad_fn=<DivBackward0>) tensor(0.0069, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) tensor(0.0068, grad_fn=<DivBackward0>) "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH0L8D0ihLXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "72048974-9976-4b61-d88c-18f3385e1c0a"
      },
      "source": [
        "## Seems to work fine here\n",
        "x_ = train_x[500:1000]\n",
        "y_ = train_y[500:1000]\n",
        "dls_trial_ = (x_,y_)\n",
        "train_epoch(dls_trial_, linear1, epoch=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0315, grad_fn=<DivBackward0>) tensor(0.0283, grad_fn=<DivBackward0>) tensor(0.0256, grad_fn=<DivBackward0>) tensor(0.0233, grad_fn=<DivBackward0>) tensor(0.0214, grad_fn=<DivBackward0>) tensor(0.0198, grad_fn=<DivBackward0>) tensor(0.0183, grad_fn=<DivBackward0>) tensor(0.0171, grad_fn=<DivBackward0>) tensor(0.0160, grad_fn=<DivBackward0>) tensor(0.0151, grad_fn=<DivBackward0>) "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ytZDZIWIiKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2336dd9a-8482-434d-9cd9-3506565ce465"
      },
      "source": [
        "### Debugging step: Writing a function that train one batch and prints the loss\n",
        "\n",
        "def train_once(x,y):\n",
        "    weights, bias = init_params()\n",
        "    for _ in range(5):\n",
        "        preds = linear1(x)\n",
        "        loss = cross_entropy(preds, y)\n",
        "        calc_grad_n_step(loss, lr)\n",
        "        print(loss)\n",
        "train_once(train_x[:5],train_y[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.7491e-05, grad_fn=<DivBackward0>)\n",
            "tensor(2.7491e-05, grad_fn=<DivBackward0>)\n",
            "tensor(2.7491e-05, grad_fn=<DivBackward0>)\n",
            "tensor(2.7491e-05, grad_fn=<DivBackward0>)\n",
            "tensor(2.7491e-05, grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hBfZ15DlsxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Same function as above for training but for batches.\n",
        "\n",
        "\n",
        "# def train_batch(dls, model, lr=0.1, *args, **kwargs):\n",
        "#     for x,y in dls:\n",
        "#         weights, bias = init_params()\n",
        "#         preds = model(x)\n",
        "#         loss = cross_entropy(preds, y)\n",
        "#         calc_grad_n_step(loss, lr)\n",
        "#         print(loss)\n",
        "\n",
        "# def train_(epoch, lr):\n",
        "#     for _ in range(epoch):\n",
        "#         train_batch(dls, linear1, lr=lr)\n",
        "#         print(f'Validation accuracy per epoch: {val_epoch(dls_test)}')\n",
        "\n",
        "\n",
        "\n",
        "# def train_batch(dls, model, epoch=10, lr=0.1, print_loss=False, *args, **kwargs):\n",
        "#         for i in range(epoch):\n",
        "#             for batch in dls:\n",
        "#                 x, y = batch\n",
        "#                 lr = lr\n",
        "#                 weights, bias = init_params()\n",
        "#                 preds = model(x)\n",
        "#                 loss = cross_entropy(preds, y)\n",
        "#                 calc_grad_n_step(loss, lr)\n",
        "#                 if print_loss:\n",
        "#                     print(loss, end=' ')\n",
        "\n",
        "## Function for validating the training. Let's see if it was worth it.\n",
        "\n",
        "# def acc_of_data(dls, model):\n",
        "#     x, y = dls \n",
        "#     preds = model(x)\n",
        "#     probs = soft_max(preds)\n",
        "#     return (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).float().mean()\n",
        "\n",
        "\n",
        "# def val_epoch(dls):\n",
        "#     stacked_acc = [acc_of_data(batch, linear1) for batch in dls]\n",
        "#     return torch.stack(stacked_acc).mean()\n",
        "\n",
        "\n",
        "# def val_acc(dls, model):\n",
        "#     cum = 0\n",
        "#     counter = 0\n",
        "#     percent_final = torch.true_divide(cum, counter)\n",
        "#     for batch in dls:\n",
        "#         x, y = batch \n",
        "#         preds = model(x)\n",
        "#         probs = soft_max(preds)\n",
        "#         acc = (torch.argmax(probs, dim=1) == torch.argmax(y, dim=1)).sum()\n",
        "#         percent_acc = torch.true_divide(acc, preds.shape[0])\n",
        "#         print(percent_acc)\n",
        "#         cum += percent_acc\n",
        "#         counter += 1\n",
        "\n",
        "#     print(f\"Validation accuracy: {percent_final}\")\n",
        "#     print(cum, counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L6Us95alJO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch(dls, linear1, lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RdV-ECvNCq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}